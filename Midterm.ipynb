{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version a but this version of numpy is 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version a but this version of numpy is 9"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shashank/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # numpy has various stat's helpers. Also contains functions to load files.\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures # we will use this to standardize the data\n",
    "from sklearn.metrics import roc_auc_score # the metric we will be tested on . You can find more here :  https://www.kaggle.com/wiki/AreaUnderCurve\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import StratifiedKFold # the cross validation method we are going to use\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(style='ticks', palette='Set2')\n",
    "import matplotlib\n",
    "#from matplotlib import pyplot as plt\n",
    "import matplotlib \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results(predictions,IDs,  filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"id,Response\\n\")\n",
    "        for i, pred in enumerate(predictions):\n",
    "            f.write(\"%d,%f\\n\" % (IDs[i], pred))\n",
    "#save_results(prediction, ID, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"train.csv\")\n",
    "test=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_columns_to_use=['var2','var4','var6','var9','var10','var11', 'var13', 'var15', 'var16', 'var17' ,'var20']\n",
    "sns.pairplot(train, vars=feature_columns_to_use, diag_kind=\"kde\", hue='response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0.00000  0.27666\n",
      "var1    28795       15\n",
      "         1      2     3     4    5    6     7\n",
      "var2  1893  13518  4503  4017  381  338  4160\n",
      "          0     1     2\n",
      "var3  12322  7193  9295\n",
      "      1.000000  0.474508  0.756788  0.738622  1.225309  1.185032  0.931966  \\\n",
      "var4       256      1064       792       905        16        23       409   \n",
      "\n",
      "      0.959900  0.526081  0.986861    ...     0.500785  1.086289  0.574031  \\\n",
      "var4       337      1272       319    ...         1278        91      1386   \n",
      "\n",
      "      1.074524  0.618884  0.872855  0.917611  1.326786  1.318063  1.235074  \n",
      "var4       118      1395       578       489         7         4        11  \n",
      "\n",
      "[1 rows x 65 columns]\n",
      "      0.000000   3.571513   21.429075  14.286050  7.143025   17.857563  \\\n",
      "var5      14404      13436        137         18        396        385   \n",
      "\n",
      "      10.714538  \n",
      "var5         34  \n",
      "      0.000000   13.636772  4.545591   9.091181 \n",
      "var6      10638        389       3192      14591\n",
      "      0   1      2    3    4\n",
      "var7  1  25  27440  357  987\n",
      "       0.00  0.12\n",
      "var8  28445   365\n",
      "      0.00   2.45   13.35  6.90   21.80\n",
      "var9  15445  10517    215   2629      4\n",
      "           0     1     2     3\n",
      "var10  15445  6434  4700  2231\n",
      "       0.00000  0.75628\n",
      "var11    20247     8563\n",
      "       2.987783  3.163881  3.109183  3.089237  4.201256  3.584074  3.356881  \\\n",
      "var12       173         3         4        11         1         2         2   \n",
      "\n",
      "       3.246354  4.049802  3.032130    ...     3.401967  3.448116  3.550805  \\\n",
      "var12         3         1        26    ...            1         2         1   \n",
      "\n",
      "       3.046031  4.042186  3.075691  3.809532  3.500620  3.288209  3.018687  \n",
      "var12        15         1         5         2         2         1        31  \n",
      "\n",
      "[1 rows x 1205 columns]\n",
      "       0   1      2    3      4\n",
      "var13  1  25  14400  191  14193\n",
      "           0     1\n",
      "var14  24650  4160\n",
      "           1     2\n",
      "var15  25141  3669\n",
      "       2.911667  2.445000  3.445000  2.978333  3.111667  3.511667  2.645000  \\\n",
      "var16      2283       583        12      3541      1695       389      1886   \n",
      "\n",
      "       3.178333  3.311667  2.845000  3.378333  2.511667  3.045000  2.578333  \\\n",
      "var16       371      3219      1515      2650      1346      2953       948   \n",
      "\n",
      "       2.711667  3.245000  2.778333  \n",
      "var16       369      1961      3089  \n",
      "       0.00000  0.55628\n",
      "var17    24570     4240\n",
      "       3.011182  2.983008  3.329794  2.971979  2.990772  4.363722  3.032030  \\\n",
      "var18         1         1         1         3         8         1         1   \n",
      "\n",
      "       2.973089  2.975721  2.970496    ...     2.974837  3.035136  3.050916  \\\n",
      "var18         9         2         2    ...           38         1         1   \n",
      "\n",
      "       2.972703  3.479652  2.971281  2.975399  2.979246  2.986131  3.040960  \n",
      "var18         4         1         2         3         2         6         1  \n",
      "\n",
      "[1 rows x 8475 columns]\n",
      "       0.581266  0.209837  0.609837  0.124123  0.266980  0.238409  0.295552  \\\n",
      "var19       170      2415      3724      1009     12352      1055      2664   \n",
      "\n",
      "       0.324123  0.352694  0.524123  0.552694  0.381266  0.409837  0.438409  \\\n",
      "var19       323        34        12       132       208       113      2775   \n",
      "\n",
      "       0.152694  0.466980  0.495552  0.181266  \n",
      "var19       109       473       175      1067  \n",
      "       0.00000  0.28999\n",
      "var20    25557     3253\n",
      "        16    1     2     3     4     5    6     7     8     9     10    11  \\\n",
      "var21  389  2453  4326  2979  1323  1589  723  1621  4853  4040  1374  1118   \n",
      "\n",
      "        12   13    14  15  \n",
      "var21  311  656  1050   5  \n"
     ]
    }
   ],
   "source": [
    "for i in test.columns:\n",
    "    if i not in ['id']:\n",
    "        print pd.DataFrame([pd.value_counts(train[i], sort=False)])#,pd.value_counts(train[i],sort=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_data(dtrain,dtest,target,ID,features=None):\n",
    "    \"\"\"Transform dataframe into numpy matrices\"\"\"\n",
    "    if features is None:\n",
    "        feature_columns_to_use = [column for column in dtrain.columns if column not in target]\n",
    "    else:\n",
    "        feature_columns_to_use = features\n",
    "\n",
    "    X_trn = dtrain.as_matrix(feature_columns_to_use)\n",
    "    y_trn = dtrain.as_matrix([target]).ravel()\n",
    "    \n",
    "    X_tst = dtest.as_matrix(feature_columns_to_use)\n",
    "    y_id = dtest.as_matrix([ID]).ravel()\n",
    "    \n",
    "    return X_trn, y_trn, X_tst, y_id\n",
    "\n",
    "def enumerate_columns(df,test,columns=None,drop_after_enumeration=False):\n",
    "    if columns is None:\n",
    "        columns_to_enumerate = df.columns\n",
    "    else:\n",
    "        columns_to_enumerate = columns\n",
    "    if drop_after_enumeration == True:\n",
    "        for column in columns_to_enumerate:\n",
    "            print column\n",
    "            enumerated_dict = {name : i for i, name in enumerate(np.unique(df[column]))}\n",
    "            df['enumerated_'+column] = df[column].map(enumerated_dict).astype(int)\n",
    "            df.drop(column,axis=1,inplace=True)\n",
    "            \n",
    "            test['enumerated_'+column] = test[column].map(enumerated_dict).astype(int)\n",
    "            test.drop(column,axis=1,inplace=True)\n",
    "        #return enumerated_dict\n",
    "    else:\n",
    "        for column in columns_to_enumerate:\n",
    "            enumerated_dict = {name : i for i, name in enumerate(np.unique(df[column]))}\n",
    "            df['enumerated_'+column] = df[column].map(enumerated_dict).astype(int) \n",
    "            \n",
    "            test['enumerated_'+column] = test[column].map(enumerated_dict).astype(int)\n",
    "        #return enumerated_dict\n",
    "def sparsify(X, X_test):\n",
    "    \"\"\"Return One-Hot encoded datasets.\"\"\"\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "    enc.fit(np.vstack((X, X_test)))\n",
    "    return enc.transform(X), enc.transform(X_test)\n",
    "def frequency(df,df_test,columns = None):\n",
    "    listcol=[]\n",
    "    if columns is None:\n",
    "        columns_to_count = df.columns\n",
    "    else:\n",
    "        columns_to_count = columns\n",
    "    for column in columns_to_count:\n",
    "        count_dict=dict(df[column].value_counts())\n",
    "        df[\"count_\"+column]=df[column].map(count_dict)\n",
    "        df_test[\"count_\"+column]=df_test[column].map(count_dict)\n",
    "        listcol.append(\"count_\"+column)\n",
    "    return listcol\n",
    "#Value_Counts 2-way\n",
    "def frequency_2_way(df, df_test, columns=None,drop_after=False,combinations=True):\n",
    "    \"\"\"Return 2-way counts\"\"\"\n",
    "    listcol=[]\n",
    "    if columns is None:\n",
    "        columns_to_count = df.columns\n",
    "    else:\n",
    "        columns_to_count = columns\n",
    "    if combinations == True:\n",
    "        for i,j in itertools.combinations(columns_to_count,2):\n",
    "            print \"Counting %s and %s\" %(i,j)\n",
    "            frequency_dict=dict(df[[i,j]].groupby([i,j]).size())\n",
    "            df[i+\"_\"+j]=pd.Series(zip(df[i],df[j])).map(frequency_dict)\n",
    "            df_test[i+\"_\"+j]=pd.Series(zip(df_test[i],df_test[j])).map(frequency_dict)\n",
    "            listcol.append(i+\"_\"+j)\n",
    "    else:\n",
    "        for (i,j) in columns_to_count:\n",
    "            print \"Counting %s and %s and %s\" %(i,j)\n",
    "            frequency_dict=dict(df[[i,j]].groupby([i,j]).size())\n",
    "            df[i+\"_\"+j]=pd.Series(zip(df[i],df[j])).map(frequency_dict)\n",
    "    if drop_after==True:\n",
    "        if combinations==True:\n",
    "            for column in columns_to_count:\n",
    "                df.drop(column,axis=1,inplace=True)\n",
    "        else:\n",
    "            for column in set([element for tup in columns_to_count for element in tup]):\n",
    "                df.drop(column,axis=1,inplace=True)\n",
    "    return listcol\n",
    "def frequency_3_way(df, df_test, columns=None,drop_after=False,combinations=True):\n",
    "    \"\"\"Return 3-way counts\"\"\"\n",
    "    listcol=[]\n",
    "    if columns is None:\n",
    "        columns_to_count = df.columns\n",
    "    else:\n",
    "        columns_to_count = columns\n",
    "    if combinations == True:\n",
    "        for i,j,k in itertools.combinations(columns_to_count,3):\n",
    "            print \"Counting %s and %s and %s\" %(i,j,k)\n",
    "            frequency_dict=dict(df[[i,j,k]].groupby([i,j,k]).size())\n",
    "            df[i+\"_\"+j+\"_\"+k]=pd.Series(zip(df[i],df[j],df[k])).map(frequency_dict)\n",
    "            df_test[i+\"_\"+j+\"_\"+k]=pd.Series(zip(df_test[i],df_test[j],df_test[k])).map(frequency_dict)\n",
    "            listcol.append(i+\"_\"+j+\"_\"+k)\n",
    "    else:\n",
    "        for (i,j,k) in columns_to_count:\n",
    "            print \"Counting %s and %s and %s\" %(i,j,k)\n",
    "            frequency_dict=dict(df[[i,j,k]].groupby([i,j,k]).size())\n",
    "            df[i+\"_\"+j+\"_\"+k]=pd.Series(zip(df[i],df[j],df[k])).map(frequency_dict)\n",
    "    if drop_after==True:\n",
    "        if combinations==True:\n",
    "            for column in columns_to_count:\n",
    "                df.drop(column,axis=1,inplace=True)\n",
    "        else:\n",
    "            for column in set([element for tup in columns_to_count for element in tup]):\n",
    "                df.drop(column,axis=1,inplace=True)\n",
    "\n",
    "    return listcol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def greedy(df,target, columns=None, params=50, gap=0.0000099):\n",
    "    train, test, y_t, y_test = cross_validation.train_test_split(df, df[target], test_size=0.2, random_state=0)\n",
    "    #train=df\n",
    "    scr = []\n",
    "    if columns is None:\n",
    "        columns=df.columns\n",
    "    diff=0.1\n",
    "    t=0\n",
    "    while t<=params:\n",
    "        score={}\n",
    "        for f in columns:\n",
    "            if f in scr:\n",
    "                pass\n",
    "            else:\n",
    "                if scr == []:\n",
    "                    past_score=0\n",
    "                else:\n",
    "                    past_score=temp\n",
    "                scr.append(f)\n",
    "                #print scr\n",
    "                #scr.append(target)\n",
    "                x_t = train[scr]\n",
    "                x_test=test[scr]\n",
    "                #x_t = x_t.dropna()\n",
    "                #x_test = x_test.dropna()\n",
    "                #y_t=x_t[target]\n",
    "                #print y_t.shape\n",
    "                if len(x_t.index) == 0:\n",
    "                    scr.remove(f)\n",
    "                    #scr.remove(target)\n",
    "                    continue\n",
    "                #x_t=x_t.drop([target],axis=1)\n",
    "                #model = linear_model.LogisticRegression(C=0.2, class_weight='balanced', random_state=12, n_jobs=-1)\n",
    "                #model.fit(x_t,y_t)\n",
    "                #model=RandomForestClassifier(n_estimators=300, criterion='gini', max_depth=10, min_samples_leaf=1, max_features=0.4, n_jobs=3, random_state=SEED) \n",
    "                #score[f]=cross_validation.cross_val_score(model,x_t,y_t,cv=5, scoring='roc_auc').mean()\n",
    "                model = XGBClassifier(learning_rate =0.05, n_estimators=100, max_depth=4, min_child_weight=10, \n",
    "                      gamma=0.2, reg_alpha=0.8, reg_lambda=0.8, #subsample=0.9, colsample_bytree=1,\n",
    "                      objective= 'binary:logistic', seed=12)\n",
    "                #score[f]=cross_validation.cross_val_score(model,x_t,y_t,cv=5, scoring='roc_auc').mean()\n",
    "                model.fit(x_t,y_t)\n",
    "                score[f]=model.score(x_test,y_test)\n",
    "                scr.remove(f)\n",
    "                #scr.remove(target)\n",
    "        sorted_score = sorted(score.items(), key=operator.itemgetter(1))\n",
    "        #print sorted_score\n",
    "        temp=max(score.iteritems(), key=operator.itemgetter(1))[1]\n",
    "        if temp-past_score < gap:\n",
    "            break\n",
    "        else:\n",
    "            added=max(score.iteritems(), key=operator.itemgetter(1))[0]\n",
    "            print \"HHHHH \\n\",added\n",
    "            scr.append(added)\n",
    "            print temp\n",
    "            t=t+1\n",
    "        print scr\n",
    "    return scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blending(dtrain,dtest,clfs,clf=LogisticRegression(C=0.2),n_folds=10,verbose=True,shuffle=True,seed=0):\n",
    "    np.random.seed(seed) # seed to shuffle the train set\n",
    "    y = dtrain['response'].values\n",
    "    skf = StratifiedKFold(y, n_folds)\n",
    "    \n",
    "    print \"Creating train and test sets for blending.\"\n",
    "    dataset_blend_train = np.zeros((dtrain.shape[0], len(clfs)))\n",
    "    dataset_blend_test = np.zeros((dtest.shape[0], len(clfs)))\n",
    "    for j, (feature_set,clf) in enumerate(clfs):\n",
    "        print j, clf,feature_set\n",
    "        X = dtrain[feature_set].values\n",
    "        \n",
    "        X_submission = dtest[feature_set].values\n",
    "        dataset_blend_test_j = np.zeros((X_submission.shape[0], len(skf)))\n",
    "        for i, (train, test) in enumerate(skf):\n",
    "            print \"Fold\", i\n",
    "            X_train = X[train]\n",
    "            y_train = y[train]\n",
    "            X_test = X[test]\n",
    "            y_test = y[test]\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_submission = clf.predict_proba(X_test)[:,1]\n",
    "            dataset_blend_train[test, j] = y_submission\n",
    "            dataset_blend_test_j[:, i] = clf.predict_proba(X_submission)[:,1]\n",
    "        dataset_blend_test[:,j] = dataset_blend_test_j.mean(1)\n",
    "\n",
    "    print \"Blending.\"\n",
    "    clf.fit(dataset_blend_train, y)\n",
    "    y_submission = clf.predict_proba(dataset_blend_test)[:,1]\n",
    "    print 'Done'\n",
    "    return y_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interaction(df, df_test, columns = None):\n",
    "    poly = PolynomialFeatures(2)\n",
    "    if columns is None:\n",
    "        columns_to_count = df.columns\n",
    "    interac_train=pd.DataFrame(poly.fit_transform(df[columns]))\n",
    "    #interac_train[target]=df[target]\n",
    "    interac_test=pd.DataFrame(poly.fit_transform(df_test[columns]))\n",
    "    return interac_train, interac_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shashank/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Interactions...\n",
      "2,3-way Counts Train, Test...\n",
      "Counting var2 and var3\n",
      "Counting var2 and var4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shashank/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting var2 and var5\n",
      "Counting var2 and var6\n",
      "Counting var2 and var7\n",
      "Counting var2 and var10\n",
      "Counting var2 and var11\n",
      "Counting var2 and var13\n",
      "Counting var2 and var14\n",
      "Counting var2 and var15\n",
      "Counting var2 and var16\n",
      "Counting var2 and var17\n",
      "Counting var2 and var19\n",
      "Counting var2 and var20\n",
      "Counting var2 and var21\n",
      "Counting var3 and var4\n",
      "Counting var3 and var5\n",
      "Counting var3 and var6\n",
      "Counting var3 and var7\n",
      "Counting var3 and var10\n",
      "Counting var3 and var11\n",
      "Counting var3 and var13\n",
      "Counting var3 and var14\n",
      "Counting var3 and var15\n",
      "Counting var3 and var16\n",
      "Counting var3 and var17\n",
      "Counting var3 and var19\n",
      "Counting var3 and var20\n",
      "Counting var3 and var21\n",
      "Counting var4 and var5\n",
      "Counting var4 and var6\n",
      "Counting var4 and var7\n",
      "Counting var4 and var10\n",
      "Counting var4 and var11\n",
      "Counting var4 and var13\n",
      "Counting var4 and var14\n",
      "Counting var4 and var15\n",
      "Counting var4 and var16\n",
      "Counting var4 and var17\n",
      "Counting var4 and var19\n",
      "Counting var4 and var20\n",
      "Counting var4 and var21\n",
      "Counting var5 and var6\n",
      "Counting var5 and var7\n",
      "Counting var5 and var10\n",
      "Counting var5 and var11\n",
      "Counting var5 and var13\n",
      "Counting var5 and var14\n",
      "Counting var5 and var15\n",
      "Counting var5 and var16\n",
      "Counting var5 and var17\n",
      "Counting var5 and var19\n",
      "Counting var5 and var20\n",
      "Counting var5 and var21\n",
      "Counting var6 and var7\n",
      "Counting var6 and var10\n",
      "Counting var6 and var11\n",
      "Counting var6 and var13\n",
      "Counting var6 and var14\n",
      "Counting var6 and var15\n",
      "Counting var6 and var16\n",
      "Counting var6 and var17\n",
      "Counting var6 and var19\n",
      "Counting var6 and var20\n",
      "Counting var6 and var21\n",
      "Counting var7 and var10\n",
      "Counting var7 and var11\n",
      "Counting var7 and var13\n",
      "Counting var7 and var14\n",
      "Counting var7 and var15\n",
      "Counting var7 and var16\n",
      "Counting var7 and var17\n",
      "Counting var7 and var19\n",
      "Counting var7 and var20\n",
      "Counting var7 and var21\n",
      "Counting var10 and var11\n",
      "Counting var10 and var13\n",
      "Counting var10 and var14\n",
      "Counting var10 and var15\n",
      "Counting var10 and var16\n",
      "Counting var10 and var17\n",
      "Counting var10 and var19\n",
      "Counting var10 and var20\n",
      "Counting var10 and var21\n",
      "Counting var11 and var13\n",
      "Counting var11 and var14\n",
      "Counting var11 and var15\n",
      "Counting var11 and var16\n",
      "Counting var11 and var17\n",
      "Counting var11 and var19\n",
      "Counting var11 and var20\n",
      "Counting var11 and var21\n",
      "Counting var13 and var14\n",
      "Counting var13 and var15\n",
      "Counting var13 and var16\n",
      "Counting var13 and var17\n",
      "Counting var13 and var19\n",
      "Counting var13 and var20\n",
      "Counting var13 and var21\n",
      "Counting var14 and var15\n",
      "Counting var14 and var16\n",
      "Counting var14 and var17\n",
      "Counting var14 and var19\n",
      "Counting var14 and var20\n",
      "Counting var14 and var21\n",
      "Counting var15 and var16\n",
      "Counting var15 and var17\n",
      "Counting var15 and var19\n",
      "Counting var15 and var20\n",
      "Counting var15 and var21\n",
      "Counting var16 and var17\n",
      "Counting var16 and var19\n",
      "Counting var16 and var20\n",
      "Counting var16 and var21\n",
      "Counting var17 and var19\n",
      "Counting var17 and var20\n",
      "Counting var17 and var21\n",
      "Counting var19 and var20\n",
      "Counting var19 and var21\n",
      "Counting var20 and var21\n",
      "Counting var2 and var3 and var4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shashank/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting var2 and var3 and var5\n",
      "Counting var2 and var3 and var6\n",
      "Counting var2 and var3 and var7\n",
      "Counting var2 and var3 and var10\n",
      "Counting var2 and var3 and var11\n",
      "Counting var2 and var3 and var13\n",
      "Counting var2 and var3 and var14\n",
      "Counting var2 and var3 and var15\n",
      "Counting var2 and var3 and var16\n",
      "Counting var2 and var3 and var17\n",
      "Counting var2 and var3 and var19\n",
      "Counting var2 and var3 and var20\n",
      "Counting var2 and var3 and var21\n",
      "Counting var2 and var4 and var5\n",
      "Counting var2 and var4 and var6\n",
      "Counting var2 and var4 and var7\n",
      "Counting var2 and var4 and var10\n",
      "Counting var2 and var4 and var11\n",
      "Counting var2 and var4 and var13\n",
      "Counting var2 and var4 and var14\n",
      "Counting var2 and var4 and var15\n",
      "Counting var2 and var4 and var16\n",
      "Counting var2 and var4 and var17\n",
      "Counting var2 and var4 and var19\n",
      "Counting var2 and var4 and var20\n",
      "Counting var2 and var4 and var21\n",
      "Counting var2 and var5 and var6\n",
      "Counting var2 and var5 and var7\n",
      "Counting var2 and var5 and var10\n",
      "Counting var2 and var5 and var11\n",
      "Counting var2 and var5 and var13\n",
      "Counting var2 and var5 and var14\n",
      "Counting var2 and var5 and var15\n",
      "Counting var2 and var5 and var16\n",
      "Counting var2 and var5 and var17\n",
      "Counting var2 and var5 and var19\n",
      "Counting var2 and var5 and var20\n",
      "Counting var2 and var5 and var21\n",
      "Counting var2 and var6 and var7\n",
      "Counting var2 and var6 and var10\n",
      "Counting var2 and var6 and var11\n",
      "Counting var2 and var6 and var13\n",
      "Counting var2 and var6 and var14\n",
      "Counting var2 and var6 and var15\n",
      "Counting var2 and var6 and var16\n",
      "Counting var2 and var6 and var17\n",
      "Counting var2 and var6 and var19\n",
      "Counting var2 and var6 and var20\n",
      "Counting var2 and var6 and var21\n",
      "Counting var2 and var7 and var10\n",
      "Counting var2 and var7 and var11\n",
      "Counting var2 and var7 and var13\n",
      "Counting var2 and var7 and var14\n",
      "Counting var2 and var7 and var15\n",
      "Counting var2 and var7 and var16\n",
      "Counting var2 and var7 and var17\n",
      "Counting var2 and var7 and var19\n",
      "Counting var2 and var7 and var20\n",
      "Counting var2 and var7 and var21\n",
      "Counting var2 and var10 and var11\n",
      "Counting var2 and var10 and var13\n",
      "Counting var2 and var10 and var14\n",
      "Counting var2 and var10 and var15\n",
      "Counting var2 and var10 and var16\n",
      "Counting var2 and var10 and var17\n",
      "Counting var2 and var10 and var19\n",
      "Counting var2 and var10 and var20\n",
      "Counting var2 and var10 and var21\n",
      "Counting var2 and var11 and var13\n",
      "Counting var2 and var11 and var14\n",
      "Counting var2 and var11 and var15\n",
      "Counting var2 and var11 and var16\n",
      "Counting var2 and var11 and var17\n",
      "Counting var2 and var11 and var19\n",
      "Counting var2 and var11 and var20\n",
      "Counting var2 and var11 and var21\n",
      "Counting var2 and var13 and var14\n",
      "Counting var2 and var13 and var15\n",
      "Counting var2 and var13 and var16\n",
      "Counting var2 and var13 and var17\n",
      "Counting var2 and var13 and var19\n",
      "Counting var2 and var13 and var20\n",
      "Counting var2 and var13 and var21\n",
      "Counting var2 and var14 and var15\n",
      "Counting var2 and var14 and var16\n",
      "Counting var2 and var14 and var17\n",
      "Counting var2 and var14 and var19\n",
      "Counting var2 and var14 and var20\n",
      "Counting var2 and var14 and var21\n",
      "Counting var2 and var15 and var16\n",
      "Counting var2 and var15 and var17\n",
      "Counting var2 and var15 and var19\n",
      "Counting var2 and var15 and var20\n",
      "Counting var2 and var15 and var21\n",
      "Counting var2 and var16 and var17\n",
      "Counting var2 and var16 and var19\n",
      "Counting var2 and var16 and var20\n",
      "Counting var2 and var16 and var21\n",
      "Counting var2 and var17 and var19\n",
      "Counting var2 and var17 and var20\n",
      "Counting var2 and var17 and var21\n",
      "Counting var2 and var19 and var20\n",
      "Counting var2 and var19 and var21\n",
      "Counting var2 and var20 and var21\n",
      "Counting var3 and var4 and var5\n",
      "Counting var3 and var4 and var6\n",
      "Counting var3 and var4 and var7\n",
      "Counting var3 and var4 and var10\n",
      "Counting var3 and var4 and var11\n",
      "Counting var3 and var4 and var13\n",
      "Counting var3 and var4 and var14\n",
      "Counting var3 and var4 and var15\n",
      "Counting var3 and var4 and var16\n",
      "Counting var3 and var4 and var17\n",
      "Counting var3 and var4 and var19\n",
      "Counting var3 and var4 and var20\n",
      "Counting var3 and var4 and var21\n",
      "Counting var3 and var5 and var6\n",
      "Counting var3 and var5 and var7\n",
      "Counting var3 and var5 and var10\n",
      "Counting var3 and var5 and var11\n",
      "Counting var3 and var5 and var13\n",
      "Counting var3 and var5 and var14\n",
      "Counting var3 and var5 and var15\n",
      "Counting var3 and var5 and var16\n",
      "Counting var3 and var5 and var17\n",
      "Counting var3 and var5 and var19\n",
      "Counting var3 and var5 and var20\n",
      "Counting var3 and var5 and var21\n",
      "Counting var3 and var6 and var7\n",
      "Counting var3 and var6 and var10\n",
      "Counting var3 and var6 and var11\n",
      "Counting var3 and var6 and var13\n",
      "Counting var3 and var6 and var14\n",
      "Counting var3 and var6 and var15\n",
      "Counting var3 and var6 and var16\n",
      "Counting var3 and var6 and var17\n",
      "Counting var3 and var6 and var19\n",
      "Counting var3 and var6 and var20\n",
      "Counting var3 and var6 and var21\n",
      "Counting var3 and var7 and var10\n",
      "Counting var3 and var7 and var11\n",
      "Counting var3 and var7 and var13\n",
      "Counting var3 and var7 and var14\n",
      "Counting var3 and var7 and var15\n",
      "Counting var3 and var7 and var16\n",
      "Counting var3 and var7 and var17\n",
      "Counting var3 and var7 and var19\n",
      "Counting var3 and var7 and var20\n",
      "Counting var3 and var7 and var21\n",
      "Counting var3 and var10 and var11\n",
      "Counting var3 and var10 and var13\n",
      "Counting var3 and var10 and var14\n",
      "Counting var3 and var10 and var15\n",
      "Counting var3 and var10 and var16\n",
      "Counting var3 and var10 and var17\n",
      "Counting var3 and var10 and var19\n",
      "Counting var3 and var10 and var20\n",
      "Counting var3 and var10 and var21\n",
      "Counting var3 and var11 and var13\n",
      "Counting var3 and var11 and var14\n",
      "Counting var3 and var11 and var15\n",
      "Counting var3 and var11 and var16\n",
      "Counting var3 and var11 and var17\n",
      "Counting var3 and var11 and var19\n",
      "Counting var3 and var11 and var20\n",
      "Counting var3 and var11 and var21\n",
      "Counting var3 and var13 and var14\n",
      "Counting var3 and var13 and var15\n",
      "Counting var3 and var13 and var16\n",
      "Counting var3 and var13 and var17\n",
      "Counting var3 and var13 and var19\n",
      "Counting var3 and var13 and var20\n",
      "Counting var3 and var13 and var21\n",
      "Counting var3 and var14 and var15\n",
      "Counting var3 and var14 and var16\n",
      "Counting var3 and var14 and var17\n",
      "Counting var3 and var14 and var19\n",
      "Counting var3 and var14 and var20\n",
      "Counting var3 and var14 and var21\n",
      "Counting var3 and var15 and var16\n",
      "Counting var3 and var15 and var17\n",
      "Counting var3 and var15 and var19\n",
      "Counting var3 and var15 and var20\n",
      "Counting var3 and var15 and var21\n",
      "Counting var3 and var16 and var17\n",
      "Counting var3 and var16 and var19\n",
      "Counting var3 and var16 and var20\n",
      "Counting var3 and var16 and var21\n",
      "Counting var3 and var17 and var19\n",
      "Counting var3 and var17 and var20\n",
      "Counting var3 and var17 and var21\n",
      "Counting var3 and var19 and var20\n",
      "Counting var3 and var19 and var21\n",
      "Counting var3 and var20 and var21\n",
      "Counting var4 and var5 and var6\n",
      "Counting var4 and var5 and var7\n",
      "Counting var4 and var5 and var10\n",
      "Counting var4 and var5 and var11\n",
      "Counting var4 and var5 and var13\n",
      "Counting var4 and var5 and var14\n",
      "Counting var4 and var5 and var15\n",
      "Counting var4 and var5 and var16\n",
      "Counting var4 and var5 and var17\n",
      "Counting var4 and var5 and var19\n",
      "Counting var4 and var5 and var20\n",
      "Counting var4 and var5 and var21\n",
      "Counting var4 and var6 and var7\n",
      "Counting var4 and var6 and var10\n",
      "Counting var4 and var6 and var11\n",
      "Counting var4 and var6 and var13\n",
      "Counting var4 and var6 and var14\n",
      "Counting var4 and var6 and var15\n",
      "Counting var4 and var6 and var16\n",
      "Counting var4 and var6 and var17\n",
      "Counting var4 and var6 and var19\n",
      "Counting var4 and var6 and var20\n",
      "Counting var4 and var6 and var21\n",
      "Counting var4 and var7 and var10\n",
      "Counting var4 and var7 and var11\n",
      "Counting var4 and var7 and var13\n",
      "Counting var4 and var7 and var14\n",
      "Counting var4 and var7 and var15\n",
      "Counting var4 and var7 and var16\n",
      "Counting var4 and var7 and var17\n",
      "Counting var4 and var7 and var19\n",
      "Counting var4 and var7 and var20\n",
      "Counting var4 and var7 and var21\n",
      "Counting var4 and var10 and var11\n",
      "Counting var4 and var10 and var13\n",
      "Counting var4 and var10 and var14\n",
      "Counting var4 and var10 and var15\n",
      "Counting var4 and var10 and var16\n",
      "Counting var4 and var10 and var17\n",
      "Counting var4 and var10 and var19\n",
      "Counting var4 and var10 and var20\n",
      "Counting var4 and var10 and var21\n",
      "Counting var4 and var11 and var13\n",
      "Counting var4 and var11 and var14\n",
      "Counting var4 and var11 and var15\n",
      "Counting var4 and var11 and var16\n",
      "Counting var4 and var11 and var17\n",
      "Counting var4 and var11 and var19\n",
      "Counting var4 and var11 and var20\n",
      "Counting var4 and var11 and var21\n",
      "Counting var4 and var13 and var14\n",
      "Counting var4 and var13 and var15\n",
      "Counting var4 and var13 and var16\n",
      "Counting var4 and var13 and var17\n",
      "Counting var4 and var13 and var19\n",
      "Counting var4 and var13 and var20\n",
      "Counting var4 and var13 and var21\n",
      "Counting var4 and var14 and var15\n",
      "Counting var4 and var14 and var16\n",
      "Counting var4 and var14 and var17\n",
      "Counting var4 and var14 and var19\n",
      "Counting var4 and var14 and var20\n",
      "Counting var4 and var14 and var21\n",
      "Counting var4 and var15 and var16\n",
      "Counting var4 and var15 and var17\n",
      "Counting var4 and var15 and var19\n",
      "Counting var4 and var15 and var20\n",
      "Counting var4 and var15 and var21\n",
      "Counting var4 and var16 and var17\n",
      "Counting var4 and var16 and var19\n",
      "Counting var4 and var16 and var20\n",
      "Counting var4 and var16 and var21\n",
      "Counting var4 and var17 and var19\n",
      "Counting var4 and var17 and var20\n",
      "Counting var4 and var17 and var21\n",
      "Counting var4 and var19 and var20\n",
      "Counting var4 and var19 and var21\n",
      "Counting var4 and var20 and var21\n",
      "Counting var5 and var6 and var7\n",
      "Counting var5 and var6 and var10\n",
      "Counting var5 and var6 and var11\n",
      "Counting var5 and var6 and var13\n",
      "Counting var5 and var6 and var14\n",
      "Counting var5 and var6 and var15\n",
      "Counting var5 and var6 and var16\n",
      "Counting var5 and var6 and var17\n",
      "Counting var5 and var6 and var19\n",
      "Counting var5 and var6 and var20\n",
      "Counting var5 and var6 and var21\n",
      "Counting var5 and var7 and var10\n",
      "Counting var5 and var7 and var11\n",
      "Counting var5 and var7 and var13\n",
      "Counting var5 and var7 and var14\n",
      "Counting var5 and var7 and var15\n",
      "Counting var5 and var7 and var16\n",
      "Counting var5 and var7 and var17\n",
      "Counting var5 and var7 and var19\n",
      "Counting var5 and var7 and var20\n",
      "Counting var5 and var7 and var21\n",
      "Counting var5 and var10 and var11\n",
      "Counting var5 and var10 and var13\n",
      "Counting var5 and var10 and var14\n",
      "Counting var5 and var10 and var15\n",
      "Counting var5 and var10 and var16\n",
      "Counting var5 and var10 and var17\n",
      "Counting var5 and var10 and var19\n",
      "Counting var5 and var10 and var20\n",
      "Counting var5 and var10 and var21\n",
      "Counting var5 and var11 and var13\n",
      "Counting var5 and var11 and var14\n",
      "Counting var5 and var11 and var15\n",
      "Counting var5 and var11 and var16\n",
      "Counting var5 and var11 and var17\n",
      "Counting var5 and var11 and var19\n",
      "Counting var5 and var11 and var20\n",
      "Counting var5 and var11 and var21\n",
      "Counting var5 and var13 and var14\n",
      "Counting var5 and var13 and var15\n",
      "Counting var5 and var13 and var16\n",
      "Counting var5 and var13 and var17\n",
      "Counting var5 and var13 and var19\n",
      "Counting var5 and var13 and var20\n",
      "Counting var5 and var13 and var21\n",
      "Counting var5 and var14 and var15\n",
      "Counting var5 and var14 and var16\n",
      "Counting var5 and var14 and var17\n",
      "Counting var5 and var14 and var19\n",
      "Counting var5 and var14 and var20\n",
      "Counting var5 and var14 and var21\n",
      "Counting var5 and var15 and var16\n",
      "Counting var5 and var15 and var17\n",
      "Counting var5 and var15 and var19\n",
      "Counting var5 and var15 and var20\n",
      "Counting var5 and var15 and var21\n",
      "Counting var5 and var16 and var17\n",
      "Counting var5 and var16 and var19\n",
      "Counting var5 and var16 and var20\n",
      "Counting var5 and var16 and var21\n",
      "Counting var5 and var17 and var19\n",
      "Counting var5 and var17 and var20\n",
      "Counting var5 and var17 and var21\n",
      "Counting var5 and var19 and var20\n",
      "Counting var5 and var19 and var21\n",
      "Counting var5 and var20 and var21\n",
      "Counting var6 and var7 and var10\n",
      "Counting var6 and var7 and var11\n",
      "Counting var6 and var7 and var13\n",
      "Counting var6 and var7 and var14\n",
      "Counting var6 and var7 and var15\n",
      "Counting var6 and var7 and var16\n",
      "Counting var6 and var7 and var17\n",
      "Counting var6 and var7 and var19\n",
      "Counting var6 and var7 and var20\n",
      "Counting var6 and var7 and var21\n",
      "Counting var6 and var10 and var11\n",
      "Counting var6 and var10 and var13\n",
      "Counting var6 and var10 and var14\n",
      "Counting var6 and var10 and var15\n",
      "Counting var6 and var10 and var16\n",
      "Counting var6 and var10 and var17\n",
      "Counting var6 and var10 and var19\n",
      "Counting var6 and var10 and var20\n",
      "Counting var6 and var10 and var21\n",
      "Counting var6 and var11 and var13\n",
      "Counting var6 and var11 and var14\n",
      "Counting var6 and var11 and var15\n",
      "Counting var6 and var11 and var16\n",
      "Counting var6 and var11 and var17\n",
      "Counting var6 and var11 and var19\n",
      "Counting var6 and var11 and var20\n",
      "Counting var6 and var11 and var21\n",
      "Counting var6 and var13 and var14\n",
      "Counting var6 and var13 and var15\n",
      "Counting var6 and var13 and var16\n",
      "Counting var6 and var13 and var17\n",
      "Counting var6 and var13 and var19\n",
      "Counting var6 and var13 and var20\n",
      "Counting var6 and var13 and var21\n",
      "Counting var6 and var14 and var15\n",
      "Counting var6 and var14 and var16\n",
      "Counting var6 and var14 and var17\n",
      "Counting var6 and var14 and var19\n",
      "Counting var6 and var14 and var20\n",
      "Counting var6 and var14 and var21\n",
      "Counting var6 and var15 and var16\n",
      "Counting var6 and var15 and var17\n",
      "Counting var6 and var15 and var19\n",
      "Counting var6 and var15 and var20\n",
      "Counting var6 and var15 and var21\n",
      "Counting var6 and var16 and var17\n",
      "Counting var6 and var16 and var19\n",
      "Counting var6 and var16 and var20\n",
      "Counting var6 and var16 and var21\n",
      "Counting var6 and var17 and var19\n",
      "Counting var6 and var17 and var20\n",
      "Counting var6 and var17 and var21\n",
      "Counting var6 and var19 and var20\n",
      "Counting var6 and var19 and var21\n",
      "Counting var6 and var20 and var21\n",
      "Counting var7 and var10 and var11\n",
      "Counting var7 and var10 and var13\n",
      "Counting var7 and var10 and var14\n",
      "Counting var7 and var10 and var15\n",
      "Counting var7 and var10 and var16\n",
      "Counting var7 and var10 and var17\n",
      "Counting var7 and var10 and var19\n",
      "Counting var7 and var10 and var20\n",
      "Counting var7 and var10 and var21\n",
      "Counting var7 and var11 and var13\n",
      "Counting var7 and var11 and var14\n",
      "Counting var7 and var11 and var15\n",
      "Counting var7 and var11 and var16\n",
      "Counting var7 and var11 and var17\n",
      "Counting var7 and var11 and var19\n",
      "Counting var7 and var11 and var20\n",
      "Counting var7 and var11 and var21\n",
      "Counting var7 and var13 and var14\n",
      "Counting var7 and var13 and var15\n",
      "Counting var7 and var13 and var16\n",
      "Counting var7 and var13 and var17\n",
      "Counting var7 and var13 and var19\n",
      "Counting var7 and var13 and var20\n",
      "Counting var7 and var13 and var21\n",
      "Counting var7 and var14 and var15\n",
      "Counting var7 and var14 and var16\n",
      "Counting var7 and var14 and var17\n",
      "Counting var7 and var14 and var19\n",
      "Counting var7 and var14 and var20\n",
      "Counting var7 and var14 and var21\n",
      "Counting var7 and var15 and var16\n",
      "Counting var7 and var15 and var17\n",
      "Counting var7 and var15 and var19\n",
      "Counting var7 and var15 and var20\n",
      "Counting var7 and var15 and var21\n",
      "Counting var7 and var16 and var17\n",
      "Counting var7 and var16 and var19\n",
      "Counting var7 and var16 and var20\n",
      "Counting var7 and var16 and var21\n",
      "Counting var7 and var17 and var19\n",
      "Counting var7 and var17 and var20\n",
      "Counting var7 and var17 and var21\n",
      "Counting var7 and var19 and var20\n",
      "Counting var7 and var19 and var21\n",
      "Counting var7 and var20 and var21\n",
      "Counting var10 and var11 and var13\n",
      "Counting var10 and var11 and var14\n",
      "Counting var10 and var11 and var15\n",
      "Counting var10 and var11 and var16\n",
      "Counting var10 and var11 and var17\n",
      "Counting var10 and var11 and var19\n",
      "Counting var10 and var11 and var20\n",
      "Counting var10 and var11 and var21\n",
      "Counting var10 and var13 and var14\n",
      "Counting var10 and var13 and var15\n",
      "Counting var10 and var13 and var16\n",
      "Counting var10 and var13 and var17\n",
      "Counting var10 and var13 and var19\n",
      "Counting var10 and var13 and var20\n",
      "Counting var10 and var13 and var21\n",
      "Counting var10 and var14 and var15\n",
      "Counting var10 and var14 and var16\n",
      "Counting var10 and var14 and var17\n",
      "Counting var10 and var14 and var19\n",
      "Counting var10 and var14 and var20\n",
      "Counting var10 and var14 and var21\n",
      "Counting var10 and var15 and var16\n",
      "Counting var10 and var15 and var17\n",
      "Counting var10 and var15 and var19\n",
      "Counting var10 and var15 and var20\n",
      "Counting var10 and var15 and var21\n",
      "Counting var10 and var16 and var17\n",
      "Counting var10 and var16 and var19\n",
      "Counting var10 and var16 and var20\n",
      "Counting var10 and var16 and var21\n",
      "Counting var10 and var17 and var19\n",
      "Counting var10 and var17 and var20\n",
      "Counting var10 and var17 and var21\n",
      "Counting var10 and var19 and var20\n",
      "Counting var10 and var19 and var21\n",
      "Counting var10 and var20 and var21\n",
      "Counting var11 and var13 and var14\n",
      "Counting var11 and var13 and var15\n",
      "Counting var11 and var13 and var16\n",
      "Counting var11 and var13 and var17\n",
      "Counting var11 and var13 and var19\n",
      "Counting var11 and var13 and var20\n",
      "Counting var11 and var13 and var21\n",
      "Counting var11 and var14 and var15\n",
      "Counting var11 and var14 and var16\n",
      "Counting var11 and var14 and var17\n",
      "Counting var11 and var14 and var19\n",
      "Counting var11 and var14 and var20\n",
      "Counting var11 and var14 and var21\n",
      "Counting var11 and var15 and var16\n",
      "Counting var11 and var15 and var17\n",
      "Counting var11 and var15 and var19\n",
      "Counting var11 and var15 and var20\n",
      "Counting var11 and var15 and var21\n",
      "Counting var11 and var16 and var17\n",
      "Counting var11 and var16 and var19\n",
      "Counting var11 and var16 and var20\n",
      "Counting var11 and var16 and var21\n",
      "Counting var11 and var17 and var19\n",
      "Counting var11 and var17 and var20\n",
      "Counting var11 and var17 and var21\n",
      "Counting var11 and var19 and var20\n",
      "Counting var11 and var19 and var21\n",
      "Counting var11 and var20 and var21\n",
      "Counting var13 and var14 and var15\n",
      "Counting var13 and var14 and var16\n",
      "Counting var13 and var14 and var17\n",
      "Counting var13 and var14 and var19\n",
      "Counting var13 and var14 and var20\n",
      "Counting var13 and var14 and var21\n",
      "Counting var13 and var15 and var16\n",
      "Counting var13 and var15 and var17\n",
      "Counting var13 and var15 and var19\n",
      "Counting var13 and var15 and var20\n",
      "Counting var13 and var15 and var21\n",
      "Counting var13 and var16 and var17\n",
      "Counting var13 and var16 and var19\n",
      "Counting var13 and var16 and var20\n",
      "Counting var13 and var16 and var21\n",
      "Counting var13 and var17 and var19\n",
      "Counting var13 and var17 and var20\n",
      "Counting var13 and var17 and var21\n",
      "Counting var13 and var19 and var20\n",
      "Counting var13 and var19 and var21\n",
      "Counting var13 and var20 and var21\n",
      "Counting var14 and var15 and var16\n",
      "Counting var14 and var15 and var17\n",
      "Counting var14 and var15 and var19\n",
      "Counting var14 and var15 and var20\n",
      "Counting var14 and var15 and var21\n",
      "Counting var14 and var16 and var17\n",
      "Counting var14 and var16 and var19\n",
      "Counting var14 and var16 and var20\n",
      "Counting var14 and var16 and var21\n",
      "Counting var14 and var17 and var19\n",
      "Counting var14 and var17 and var20\n",
      "Counting var14 and var17 and var21\n",
      "Counting var14 and var19 and var20\n",
      "Counting var14 and var19 and var21\n",
      "Counting var14 and var20 and var21\n",
      "Counting var15 and var16 and var17\n",
      "Counting var15 and var16 and var19\n",
      "Counting var15 and var16 and var20\n",
      "Counting var15 and var16 and var21\n",
      "Counting var15 and var17 and var19\n",
      "Counting var15 and var17 and var20\n",
      "Counting var15 and var17 and var21\n",
      "Counting var15 and var19 and var20\n",
      "Counting var15 and var19 and var21\n",
      "Counting var15 and var20 and var21\n",
      "Counting var16 and var17 and var19\n",
      "Counting var16 and var17 and var20\n",
      "Counting var16 and var17 and var21\n",
      "Counting var16 and var19 and var20\n",
      "Counting var16 and var19 and var21\n",
      "Counting var16 and var20 and var21\n",
      "Counting var17 and var19 and var20\n",
      "Counting var17 and var19 and var21\n",
      "Counting var17 and var20 and var21\n",
      "Counting var19 and var20 and var21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shashank/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/frame.py:2320: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n",
      "/Users/shashank/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/shashank/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/shashank/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/indexing.py:426: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8f358d88b560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m#print \"Greedy Selection...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m#preds=greedy(train,target, columns=predictors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterac_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterac_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "SEED=12\n",
    "# === load data into numpy arrays === #\n",
    "filename=\"my_name\" # name prefix - you could put your name, like marios_mich\n",
    "train=pd.read_csv(\"train.csv\")\n",
    "test=pd.read_csv(\"test.csv\")\n",
    "ID=test['id']\n",
    "target='response'\n",
    "train=train.drop(['id','var9','var1','var8'],axis=1)\n",
    "test=test.drop(['id','var9','var1','var8'],axis=1)\n",
    "#model = LogisticRegression(C=1)  # Sample of LogisticRegression model. We will adjust the C value base don our 5-fold CV\n",
    "#model=RandomForestClassifier(n_estimators=300, criterion='gini', max_depth=10, min_samples_leaf=1, max_features=0.4, n_jobs=3, random_state=SEED) \n",
    "model = XGBClassifier(learning_rate =0.05, n_estimators=300, max_depth=4, min_child_weight=20, \n",
    "                     gamma=0.2, reg_alpha=0.9, reg_lambda=0.9, subsample=0.9, colsample_bytree=1,\n",
    "                     objective= 'binary:logistic', seed=12)\n",
    "\n",
    "continuous=['var12','var18']\n",
    "y_train=train[target]\n",
    "extra_train=train[continuous]\n",
    "extra_test=test[continuous]\n",
    "predictors = [x for x in train.columns if (x not in target) and (x not in continuous)]\n",
    "rows=train.shape[0]\n",
    "train=train.drop(target,axis=1)\n",
    "train=train.drop(continuous,axis=1)\n",
    "test=test.drop(continuous,axis=1)\n",
    "result = pd.concat([train,test])\n",
    "\n",
    "#print \"Enumerating Train and Test (on basis of Train)\"\n",
    "#enum_dict=enumerate_columns(train,test,columns=predictors,drop_after_enumeration=True)\n",
    "\n",
    "predictors=train.columns\n",
    "list1=frequency(result, test, columns=predictors)\n",
    "train=result[:rows]\n",
    "#train[continuous]=extra_train\n",
    "train[target]=y_train\n",
    "#test[continuous]=extra_test\n",
    "\n",
    "# scaler=StandardScaler()\n",
    "# train[continuous] = scaler.fit_transform(train[continuous])\n",
    "# test[continuous] = scaler.fit_transform(test[continuous])\n",
    "\n",
    "\n",
    "\n",
    "print \"Making Interactions...\"\n",
    "interac_train, interac_test=interaction(train,test,columns=list1)\n",
    "predic = interac_train.columns\n",
    "interac_train[target]=y_train\n",
    "#pred=greedy(interac_train, target, columns=predic)\n",
    "\n",
    "print \"2,3-way Counts Train, Test...\"\n",
    "list2=frequency_2_way(train,test, columns=predictors)\n",
    "list3=frequency_3_way(train,test, columns=predictors)\n",
    "\n",
    "#train=result[:rows]\n",
    "train[continuous]=extra_train\n",
    "train[target]=y_train\n",
    "#test=result[rows:]\n",
    "test[continuous]=extra_test\n",
    "scaler=StandardScaler()\n",
    "train[continuous] = scaler.fit_transform(train[continuous])\n",
    "test[continuous] = scaler.fit_transform(test[continuous])\n",
    "\n",
    "#predictors = [x for x in train.columns if (x not in target)]\n",
    "#print \"Greedy Selection...\"\n",
    "#preds=greedy(train,target, columns=predictors)\n",
    "train[predic]=interac_train[predic]\n",
    "test[predic]=interac_test[predic]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['var10',\n",
       " 'var2',\n",
       " 'var21',\n",
       " 'var15',\n",
       " 'var6',\n",
       " 'var4',\n",
       " 'var19',\n",
       " 'var5',\n",
       " 'var7',\n",
       " 'var17',\n",
       " 'var20']"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train[target]=y\n",
    "#train.info(verbose=True, null_counts=True)\n",
    "preds=greedy(train,target, columns=predictors)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[predic]=interac_train[predic]\n",
    "test[predic]=interac_test[predic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shashank/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HHHHH \n",
      "102\n",
      "0.732731690385\n",
      "[102]\n",
      "HHHHH \n",
      "25\n",
      "0.742103436307\n",
      "[102, 25]\n",
      "HHHHH \n",
      "137\n",
      "0.750086775425\n",
      "[102, 25, 137]\n",
      "HHHHH \n",
      "136\n",
      "0.75199583478\n",
      "[102, 25, 137, 136]\n",
      "HHHHH \n",
      "92\n",
      "0.75216938563\n",
      "[102, 25, 137, 136, 92]\n",
      "HHHHH \n",
      "109\n",
      "0.752690038181\n",
      "[102, 25, 137, 136, 92, 109]\n",
      "HHHHH \n",
      "112\n",
      "0.753557792433\n",
      "[102, 25, 137, 136, 92, 109, 112]\n",
      "HHHHH \n",
      "19\n",
      "0.754425546685\n",
      "[102, 25, 137, 136, 92, 109, 112, 19]\n",
      "HHHHH \n",
      "37\n",
      "0.754946199236\n",
      "[102, 25, 137, 136, 92, 109, 112, 19, 37]\n",
      "HHHHH \n",
      "2\n",
      "0.755466851788\n",
      "[102, 25, 137, 136, 92, 109, 112, 19, 37, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[102, 25, 137, 136, 92, 109, 112, 19, 37, 2]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tempo=predic\n",
    "# predic=list(predic).append(target)\n",
    "tempo=train[range(153)]\n",
    "tempo[target]=train[target]\n",
    "preds=greedy(tempo,target, columns=range(153))\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['var2',\n",
       " 'var3',\n",
       " 'var4',\n",
       " 'var5',\n",
       " 'var6',\n",
       " 'var7',\n",
       " 'var10',\n",
       " 'var11',\n",
       " 'var13',\n",
       " 'var14',\n",
       " 'var15',\n",
       " 'var16',\n",
       " 'var17',\n",
       " 'var19',\n",
       " 'var20',\n",
       " 'var21',\n",
       " 'var18',\n",
       " 'var12']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pred=list(['var2','var3', 'var4','var5','var6',\n",
    "              'var7','var10','var11','var13',\n",
    "              'var14','var15','var16','var17','var19',\n",
    "              'var20','var21','var18','var12'])\n",
    "rf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0.2, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=20, missing=None, n_estimators=300, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0.9, reg_lambda=0.9,\n",
       "       scale_pos_weight=1, seed=3, silent=True, subsample=0.9)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tempo[sc],tempo[target])\n",
    "#tempo[target]\n",
    "#train.info(verbose=True,null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train size: 23048. test size: 5762, cols: 868 \n",
      "Creating train and test sets for blending.\n",
      "0 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features=0.4, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=3,\n",
      "            oob_score=False, random_state=12, verbose=0, warm_start=False) ['var2', 'var3', 'var4', 'var5', 'var6', 'var7', 'var10', 'var11', 'var13', 'var14', 'var15', 'var16', 'var17', 'var19', 'var20', 'var21', 'var18', 'var12']\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "1 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0.2, learning_rate=0.05, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=20, missing=None, n_estimators=300, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.9, reg_lambda=0.9,\n",
      "       scale_pos_weight=1, seed=3, silent=True, subsample=0.9) [102, 25, 137, 136, 92, 109, 112, 19, 37, 2]\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "2 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0.2, learning_rate=0.06, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=20, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.9, reg_lambda=0.9,\n",
      "       scale_pos_weight=1, seed=3, silent=True, subsample=0.9) [102, 25, 137, 136, 92, 109, 112, 19, 37, 2]\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "Blending.\n",
      "Done\n",
      "AUC (fold 1/5): 0.825805\n",
      " train size: 23048. test size: 5762, cols: 868 \n",
      "Creating train and test sets for blending.\n",
      "0 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features=0.4, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=3,\n",
      "            oob_score=False, random_state=12, verbose=0, warm_start=False) ['var2', 'var3', 'var4', 'var5', 'var6', 'var7', 'var10', 'var11', 'var13', 'var14', 'var15', 'var16', 'var17', 'var19', 'var20', 'var21', 'var18', 'var12']\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "1 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0.2, learning_rate=0.05, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=20, missing=None, n_estimators=300, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.9, reg_lambda=0.9,\n",
      "       scale_pos_weight=1, seed=3, silent=True, subsample=0.9) [102, 25, 137, 136, 92, 109, 112, 19, 37, 2]\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "2 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0.2, learning_rate=0.06, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=20, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.9, reg_lambda=0.9,\n",
      "       scale_pos_weight=1, seed=3, silent=True, subsample=0.9) [102, 25, 137, 136, 92, 109, 112, 19, 37, 2]\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "Blending.\n",
      "Done\n",
      "AUC (fold 2/5): 0.828479\n",
      " train size: 23048. test size: 5762, cols: 868 \n",
      "Creating train and test sets for blending.\n",
      "0 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features=0.4, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=3,\n",
      "            oob_score=False, random_state=12, verbose=0, warm_start=False) ['var2', 'var3', 'var4', 'var5', 'var6', 'var7', 'var10', 'var11', 'var13', 'var14', 'var15', 'var16', 'var17', 'var19', 'var20', 'var21', 'var18', 'var12']\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "1 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0.2, learning_rate=0.05, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=20, missing=None, n_estimators=300, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.9, reg_lambda=0.9,\n",
      "       scale_pos_weight=1, seed=3, silent=True, subsample=0.9) [102, 25, 137, 136, 92, 109, 112, 19, 37, 2]\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "2 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0.2, learning_rate=0.06, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=20, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.9, reg_lambda=0.9,\n",
      "       scale_pos_weight=1, seed=3, silent=True, subsample=0.9) [102, 25, 137, 136, 92, 109, 112, 19, 37, 2]\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "Blending.\n",
      "Done\n",
      "AUC (fold 3/5): 0.832246\n",
      " train size: 23048. test size: 5762, cols: 868 \n",
      "Creating train and test sets for blending.\n",
      "0 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features=0.4, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=3,\n",
      "            oob_score=False, random_state=12, verbose=0, warm_start=False) ['var2', 'var3', 'var4', 'var5', 'var6', 'var7', 'var10', 'var11', 'var13', 'var14', 'var15', 'var16', 'var17', 'var19', 'var20', 'var21', 'var18', 'var12']\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "1 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0.2, learning_rate=0.05, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=20, missing=None, n_estimators=300, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.9, reg_lambda=0.9,\n",
      "       scale_pos_weight=1, seed=3, silent=True, subsample=0.9) [102, 25, 137, 136, 92, 109, 112, 19, 37, 2]\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "2 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0.2, learning_rate=0.06, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=20, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.9, reg_lambda=0.9,\n",
      "       scale_pos_weight=1, seed=3, silent=True, subsample=0.9) [102, 25, 137, 136, 92, 109, 112, 19, 37, 2]\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "Blending.\n",
      "Done\n",
      "AUC (fold 4/5): 0.818018\n",
      " train size: 23048. test size: 5762, cols: 868 \n",
      "Creating train and test sets for blending.\n",
      "0 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features=0.4, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=3,\n",
      "            oob_score=False, random_state=12, verbose=0, warm_start=False) ['var2', 'var3', 'var4', 'var5', 'var6', 'var7', 'var10', 'var11', 'var13', 'var14', 'var15', 'var16', 'var17', 'var19', 'var20', 'var21', 'var18', 'var12']\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "1 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0.2, learning_rate=0.05, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=20, missing=None, n_estimators=300, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.9, reg_lambda=0.9,\n",
      "       scale_pos_weight=1, seed=3, silent=True, subsample=0.9) [102, 25, 137, 136, 92, 109, 112, 19, 37, 2]\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "2 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0.2, learning_rate=0.06, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=20, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.9, reg_lambda=0.9,\n",
      "       scale_pos_weight=1, seed=3, silent=True, subsample=0.9) [102, 25, 137, 136, 92, 109, 112, 19, 37, 2]\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "Blending.\n",
      "Done\n",
      "AUC (fold 5/5): 0.822269\n",
      " Average AUC: 0.825364\n"
     ]
    }
   ],
   "source": [
    "#preds=['var12','var18','enumerated_var10_enumerated_var13_enumerated_var17', 'enumerated_var13_enumerated_var15', 'enumerated_var2_enumerated_var3_enumerated_var13', 'enumerated_var11_enumerated_var13_enumerated_var17', 'enumerated_var13_enumerated_var20_enumerated_var21']\n",
    "#new=train[preds]\n",
    "#new[target]=train[target]\n",
    "#test.fillna(0)\n",
    "#test['id']=ID\n",
    "#X, _, X_test,_=parse_data(train,test,target,'id')\n",
    "ids=ID\n",
    "#y=new[target]\n",
    "#train[target]=y\n",
    "#train.drop(target,axis=1, inplace=True)\n",
    "\n",
    "#X, X_test = sparsify(X, X_test)\n",
    "# === load data into numpy arrays === #\n",
    "# print (\"loading training data\")\n",
    "# X=np.loadtxt(\"train.csv\",skiprows=1, delimiter=\",\", usecols=[i for i in range (1, 22)]) # 1 is inclusive and 22 exclusive. so it is [1,21] basically. We skip 1 row since the first one is headers\n",
    "# print (\"loading labels\")    \n",
    "# y=np.loadtxt(\"train.csv\",skiprows=1, delimiter=\",\", usecols=[22]) # The last one - the respnse variable   \n",
    "# print (\"loading test data\")\n",
    "# X_test=np.loadtxt(\"test.csv\",skiprows=1, delimiter=\",\", usecols=[i for i in range (1, 22)]) # 1 is inclusive and 22 exclusive. so it is [1,21] basically\n",
    "# print (\"loading ids\")    \n",
    "# ids=np.loadtxt(\"test.csv\",skiprows=1, delimiter=\",\", usecols=[0]) # The first column is the id\n",
    "rf_model=RandomForestClassifier(n_estimators=300, criterion='gini', max_depth=10, min_samples_leaf=1, max_features=0.4, n_jobs=3, random_state=SEED) \n",
    "model = XGBClassifier(learning_rate =0.05, n_estimators=300, max_depth=4, min_child_weight=20, \n",
    "                     gamma=0.2, reg_alpha=0.9, reg_lambda=0.9, subsample=0.9, colsample_bytree=1,\n",
    "                     objective= 'binary:logistic', seed=3)\n",
    "model2 = XGBClassifier(learning_rate =0.06, n_estimators=100, max_depth=5, min_child_weight=20, \n",
    "                     gamma=0.2, reg_alpha=0.9, reg_lambda=0.9, subsample=0.9, colsample_bytree=1,\n",
    "                     objective= 'binary:logistic', seed=3)\n",
    "clfs=[(rf_pred,rf_model),(preds,model), (pred,model2)]\n",
    "# === training & metrics === #\n",
    "mean_auc = 0.0\n",
    "n = 5  # number of folds in strattified cv\n",
    "kfolder=StratifiedKFold(y, n_folds= n,shuffle=True, random_state=12)     \n",
    "i=0\n",
    "for train_index, test_index in kfolder: # for each train and test pair of indices in the kfolder object\n",
    "    # creaning and validation sets\n",
    "#     X_train, X_cv = X[train_index], X[test_index]\n",
    "#     y_train, y_cv = np.array(y)[train_index], np.array(y)[test_index]\n",
    "    X_train, X_cv=train.iloc[train_index], train.iloc[test_index]\n",
    "    y_train, y_cv=y.iloc[train_index], y.iloc[test_index]\n",
    "    print (\" train size: %d. test size: %d, cols: %d \" % ((X_train.shape[0]) ,(X_cv.shape[0]) ,(X_train.shape[1]) ))\n",
    "\n",
    "    # do scalling\n",
    "#     scaler=StandardScaler()\n",
    "#     X_train = scaler.fit_transform(X_train)\n",
    "#     X_cv = scaler.transform(X_cv)\n",
    "\n",
    "    # train model\n",
    "    #model.fit(X_train,y_train)\n",
    "    # make predictions in probabilities\n",
    "    #prediction=model.predict_proba(X_cv)[:,1]\n",
    "    # compute AUC metric for this CV fold\n",
    "    \n",
    "    prediction=blending(X_train,X_cv,clfs)\n",
    "    roc_auc = roc_auc_score(y_cv, prediction)\n",
    "    print \"AUC (fold %d/%d): %f\" % (i + 1, n, roc_auc)\n",
    "    mean_auc += roc_auc\n",
    "    i+=1\n",
    "\n",
    "mean_auc/=n\n",
    "print (\" Average AUC: %f\" % (mean_auc) )        \n",
    "\n",
    "# do scalling\n",
    "# scaler=StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "# X_test = scaler.transform(X_test) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train and test sets for blending.\n",
      "0 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features=0.4, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=3,\n",
      "            oob_score=False, random_state=12, verbose=0, warm_start=False) ['var2', 'var3', 'var4', 'var5', 'var6', 'var7', 'var10', 'var11', 'var13', 'var14', 'var15', 'var16', 'var17', 'var19', 'var20', 'var21', 'var18', 'var12']\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "1 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0.2, learning_rate=0.05, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=20, missing=None, n_estimators=300, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.9, reg_lambda=0.9,\n",
      "       scale_pos_weight=1, seed=3, silent=True, subsample=0.9) [102, 25, 137, 136, 92, 109, 112, 19, 37, 2]\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "2 XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0.2, learning_rate=0.06, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=20, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.9, reg_lambda=0.9,\n",
      "       scale_pos_weight=1, seed=3, silent=True, subsample=0.9) [102, 25, 137, 136, 92, 109, 112, 19, 37, 2]\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "Blending.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# new, cv, y_t, y_cv = cross_validation.train_test_split(train, train[target], test_size=0.2, random_state=0)\n",
    "# new[target]=y_t\n",
    "\n",
    "#rf_mod=RandomForestClassifier(n_estimators=300, criterion='entropy', max_depth=10, min_samples_leaf=1, max_features=0.4, n_jobs=3, random_state=SEED) \n",
    "#ett_mod=ExtraTreesClassifier(n_estimators=300, n_jobs=-1, criterion='entropy')\n",
    "#gbm=GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=10, n_estimators=100)\n",
    "#clfs=[(preds,model), (rf_pred,rf_mod)]\n",
    "prediction=blending(train,test,clfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission my_name_submission_0_825363568067.csv has been generated!\n"
     ]
    }
   ],
   "source": [
    "#make final model\n",
    "#X=new[preds]\n",
    "#model.fit(train,y)\n",
    "\n",
    "#make predictions in probabilities\n",
    "#print roc_auc_score(y_cv, prediction)\n",
    "\n",
    "#prediction=model.predict_proba(test)[:,1]    \n",
    "#create submission file \n",
    "save_results(prediction, ids,  filename+\"_submission_\" +str(mean_auc).replace(\".\",\"_\") + \".csv\") # putting the actuall AUC (of cv) in the file's name for reference\n",
    "\n",
    "print(\"Submission %s has been generated!\" % ( filename+\"_submission_\" +str(mean_auc).replace(\".\",\"_\") + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)\n",
    "#test.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28810,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temporary.remove('var12')\n",
    "temporary.remove('var18')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enumerated_var10_enumerated_var13_enumerated_var17',\n",
       " 'enumerated_var13_enumerated_var15',\n",
       " 'enumerated_var2_enumerated_var3_enumerated_var13',\n",
       " 'enumerated_var11_enumerated_var13_enumerated_var17',\n",
       " 'enumerated_var13_enumerated_var20_enumerated_var21',\n",
       " 'enumerated_var13_enumerated_var14_enumerated_var21',\n",
       " 'enumerated_var5_enumerated_var13_enumerated_var20',\n",
       " 'enumerated_var13_enumerated_var15_enumerated_var17',\n",
       " 'enumerated_var2_enumerated_var4_enumerated_var21',\n",
       " 'var12',\n",
       " 'var18',\n",
       " 'var12',\n",
       " 'var18']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing: 0 /Users/shashank/Desktop/MS/1-2/ML/Midterm/83505.csv\n",
      "parsing: 1 /Users/shashank/Desktop/MS/1-2/ML/Midterm/83255.csv\n",
      "wrote to out.csv\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "loc_outfile = 'out.csv'\n",
    "def kaggle_bag(array, loc_outfile, weights=[0.8,0.2],method=\"average\"):\n",
    "  if method == \"average\":\n",
    "    scores = defaultdict(float)\n",
    "  with open(loc_outfile,\"wb\") as outfile:\n",
    "    for i, glob_file in enumerate(array):\n",
    "      print \"parsing:\", i,glob_file\n",
    "      # sort glob_file by first column, ignoring the first line\n",
    "      lines = open(glob_file).readlines()\n",
    "      lines = [lines[0]] + sorted(lines[1:])\n",
    "      for e, line in enumerate( lines ):\n",
    "        if i == 0 and e == 0:\n",
    "          outfile.write(line)\n",
    "        if e > 0:\n",
    "          row = line.strip().split(\",\")\n",
    "          scores[(e,row[0])] += float(row[1])*weights[i]\n",
    "    for j,k in sorted(scores):\n",
    "      outfile.write(\"%s,%f\\n\"%(k,(scores[(j,k)])))\n",
    "    print(\"wrote to %s\"%loc_outfile)\n",
    "array=[ os.getcwd()+'/83505.csv', os.getcwd()+'/83255.csv']\n",
    "kaggle_bag(array, loc_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enumerated_var10_enumerated_var13_enumerated_var17',\n",
       " 'enumerated_var2_enumerated_var3_enumerated_var13',\n",
       " 'enumerated_var11_enumerated_var13_enumerated_var17',\n",
       " 'enumerated_var13_enumerated_var20_enumerated_var21',\n",
       " 'enumerated_var13_enumerated_var14_enumerated_var21',\n",
       " 'enumerated_var5_enumerated_var13_enumerated_var20',\n",
       " 'enumerated_var13_enumerated_var15_enumerated_var17',\n",
       " 'enumerated_var2_enumerated_var4_enumerated_var21',\n",
       " 'enumerated_var3_enumerated_var10',\n",
       " 'enumerated_var10',\n",
       " 'enumerated_var15',\n",
       " 'enumerated_var2',\n",
       " 'enumerated_var21',\n",
       " 'enumerated_var13',\n",
       " 'var18',\n",
       " 'var12',\n",
       " 'enumerated_var19',\n",
       " 'enumerated_var20',\n",
       " 'enumerated_var11',\n",
       " 'enumerated_var7']"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temporary.remove('var12')\n",
    "# temporary.remove('var18')\n",
    "#Phani chosen parameters\n",
    "#preds=['enumerated_var10','var12','var18','enumerated_var21','enumerated_var15','enumerated_var6','enumerated_var2','enumerated_var4','enumerated_var3','enumerated_var7','enumerated_var16','enumerated_var5',]\n",
    "#Greedy selected on Logistic \n",
    "'''\n",
    "preds_top_3=\n",
    "['enumerated_var10_enumerated_var13_enumerated_var17',\n",
    " 'enumerated_var2_enumerated_var3_enumerated_var13',\n",
    " 'enumerated_var11_enumerated_var13_enumerated_var17',\n",
    " 'enumerated_var13_enumerated_var20_enumerated_var21',\n",
    " 'enumerated_var13_enumerated_var14_enumerated_var21',\n",
    " 'enumerated_var5_enumerated_var13_enumerated_var20',\n",
    " 'enumerated_var13_enumerated_var15_enumerated_var17',\n",
    " 'enumerated_var2_enumerated_var4_enumerated_var21'\n",
    " ]\n",
    "pred_top_2=\n",
    "['enumerated_var3_enumerated_var10', \n",
    " 'enumerated_var3_enumerated_var15',\n",
    " 'enumerated_var2_enumerated_var6',\n",
    " 'enumerated_var19_enumerated_var21',\n",
    " 'enumerated_var10_enumerated_var15',\n",
    " 'enumerated_var3_enumerated_var20'\n",
    "]\n",
    "preds_single=\n",
    "['enumerated_var10', \n",
    " 'enumerated_var15', \n",
    " 'enumerated_var2', \n",
    " 'enumerated_var21', \n",
    " 'enumerated_var13', \n",
    " 'var18', \n",
    " 'var12',\n",
    " 'enumerated_var19',\n",
    " 'enumerated_var20',\n",
    " 'enumerated_var11',\n",
    " 'enumerated_var7'\n",
    "]\n",
    "'''\n",
    "preds=['enumerated_var10_enumerated_var13_enumerated_var17',\n",
    " 'enumerated_var2_enumerated_var3_enumerated_var13',\n",
    " 'enumerated_var11_enumerated_var13_enumerated_var17',\n",
    " 'enumerated_var13_enumerated_var20_enumerated_var21',\n",
    " 'enumerated_var13_enumerated_var14_enumerated_var21',\n",
    " 'enumerated_var5_enumerated_var13_enumerated_var20',\n",
    " 'enumerated_var13_enumerated_var15_enumerated_var17',\n",
    " 'enumerated_var2_enumerated_var4_enumerated_var21',\n",
    " 'enumerated_var3_enumerated_var10', \n",
    " #'enumerated_var3_enumerated_var15',\n",
    " #'enumerated_var2_enumerated_var6',\n",
    " #'enumerated_var19_enumerated_var21',\n",
    " #'enumerated_var10_enumerated_var15',\n",
    " #'enumerated_var3_enumerated_var20',\n",
    " 'enumerated_var10', \n",
    " 'enumerated_var15', \n",
    " 'enumerated_var2', \n",
    " 'enumerated_var21', \n",
    " 'enumerated_var13', \n",
    " 'var18', \n",
    " 'var12',\n",
    " 'enumerated_var19',\n",
    " 'enumerated_var20',\n",
    " 'enumerated_var11',\n",
    " 'enumerated_var7'\n",
    "]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "167",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e541f506e14b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m87\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m167\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m167\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/shashank/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1967\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shashank/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1974\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shashank/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shashank/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3211\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3212\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3213\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shashank/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1757\u001b[0m                                  'backfill or nearest lookups')\n\u001b[1;32m   1758\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         indexer = self.get_indexer([key], method=method,\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3979)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3843)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12265)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12216)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 167"
     ]
    }
   ],
   "source": [
    "pred=[7, 11, 21, 13, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0.2, learning_rate=0.06, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=20, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0.9, reg_lambda=0.9,\n",
       "       scale_pos_weight=1, seed=3, silent=True, subsample=0.9),\n",
       "          fit_params={}, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'n_estimators': [20, 40, 70, 100, 200, 300, 350, 250, 320], 'gamma': [0.2, 0.3]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(learning_rate =0.06, \n",
    "                      n_estimators=100, \n",
    "                      max_depth=5, \n",
    "                      min_child_weight=20, \n",
    "                     gamma=0.2, \n",
    "                      reg_alpha=0.9, \n",
    "                      reg_lambda=0.9, \n",
    "                      subsample=0.9, \n",
    "                      colsample_bytree=1,\n",
    "                     objective= 'binary:logistic', \n",
    "                      seed=3)\n",
    "clf=RandomizedSearchCV(model,\n",
    "    {\n",
    "        #'learning_rate':[i/100.0 for i in range(5,20)],\n",
    "         #'min_child_weight': [5,6,7,8],\n",
    "         #'max_depth': [5,10,15,18,12,50],\n",
    "         'n_estimators':[20,40,70,100,200,300,350,250,320] ,\n",
    "        'gamma':[i/10.0 for i in range(2,4)],\n",
    "        #'reg_alpha':[0.2,0.3,0.4,0.5],\n",
    "        #'reg_lambda':[0.3,0.4,0.5,0.6]\n",
    "        #'colsample_bytree': [0.6,0.7,0.8,0.85,0.9],\n",
    "    },\n",
    "    cv=5,\n",
    "    n_jobs=1,\n",
    "    verbose=5,\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=250, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=250, gamma=0.2, score=0.810951 -   2.4s\n",
      "[CV] n_estimators=250, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=250, gamma=0.2, score=0.810734 -   2.3s\n",
      "[CV] n_estimators=250, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=250, gamma=0.2, score=0.815581 -   2.2s\n",
      "[CV] n_estimators=250, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=250, gamma=0.2, score=0.807219 -   2.2s\n",
      "[CV] n_estimators=250, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=250, gamma=0.2, score=0.810762 -   2.2s\n",
      "[CV] n_estimators=40, gamma=0.2 ......................................\n",
      "[CV] ............. n_estimators=40, gamma=0.2, score=0.805275 -   0.4s\n",
      "[CV] n_estimators=40, gamma=0.2 ......................................\n",
      "[CV] ............. n_estimators=40, gamma=0.2, score=0.806644 -   0.4s\n",
      "[CV] n_estimators=40, gamma=0.2 ......................................\n",
      "[CV] ............. n_estimators=40, gamma=0.2, score=0.814554 -   0.4s\n",
      "[CV] n_estimators=40, gamma=0.2 ......................................\n",
      "[CV] ............. n_estimators=40, gamma=0.2, score=0.804056 -   0.4s\n",
      "[CV] n_estimators=40, gamma=0.2 ......................................\n",
      "[CV] ............. n_estimators=40, gamma=0.2, score=0.808850 -   0.4s\n",
      "[CV] n_estimators=200, gamma=0.3 .....................................\n",
      "[CV] ............ n_estimators=200, gamma=0.3, score=0.811423 -   2.1s\n",
      "[CV] n_estimators=200, gamma=0.3 .....................................\n",
      "[CV] ............ n_estimators=200, gamma=0.3, score=0.811038 -   1.9s\n",
      "[CV] n_estimators=200, gamma=0.3 .....................................\n",
      "[CV] ............ n_estimators=200, gamma=0.3, score=0.815998 -   1.8s\n",
      "[CV] n_estimators=200, gamma=0.3 .....................................\n",
      "[CV] ............ n_estimators=200, gamma=0.3, score=0.807842 -   1.8s\n",
      "[CV] n_estimators=200, gamma=0.3 .....................................\n",
      "[CV] ............ n_estimators=200, gamma=0.3, score=0.810713 -   2.0s\n",
      "[CV] n_estimators=350, gamma=0.3 .....................................\n",
      "[CV] ............ n_estimators=350, gamma=0.3, score=0.810119 -   4.0s\n",
      "[CV] n_estimators=350, gamma=0.3 .....................................\n",
      "[CV] ............ n_estimators=350, gamma=0.3, score=0.809044 -   3.6s\n",
      "[CV] n_estimators=350, gamma=0.3 .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks       | elapsed:   30.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ n_estimators=350, gamma=0.3, score=0.814390 -   3.6s\n",
      "[CV] n_estimators=350, gamma=0.3 .....................................\n",
      "[CV] ............ n_estimators=350, gamma=0.3, score=0.807067 -   4.0s\n",
      "[CV] n_estimators=350, gamma=0.3 .....................................\n",
      "[CV] ............ n_estimators=350, gamma=0.3, score=0.809168 -   3.7s\n",
      "[CV] n_estimators=320, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=320, gamma=0.2, score=0.810543 -   3.3s\n",
      "[CV] n_estimators=320, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=320, gamma=0.2, score=0.809924 -   3.0s\n",
      "[CV] n_estimators=320, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=320, gamma=0.2, score=0.814921 -   3.5s\n",
      "[CV] n_estimators=320, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=320, gamma=0.2, score=0.806815 -   2.9s\n",
      "[CV] n_estimators=320, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=320, gamma=0.2, score=0.810001 -   3.5s\n",
      "[CV] n_estimators=100, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=100, gamma=0.2, score=0.811923 -   1.1s\n",
      "[CV] n_estimators=100, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=100, gamma=0.2, score=0.811226 -   1.0s\n",
      "[CV] n_estimators=100, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=100, gamma=0.2, score=0.816729 -   1.0s\n",
      "[CV] n_estimators=100, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=100, gamma=0.2, score=0.807815 -   1.0s\n",
      "[CV] n_estimators=100, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=100, gamma=0.2, score=0.810680 -   0.9s\n",
      "[CV] n_estimators=300, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=300, gamma=0.2, score=0.810871 -   2.8s\n",
      "[CV] n_estimators=300, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=300, gamma=0.2, score=0.810121 -   2.8s\n",
      "[CV] n_estimators=300, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=300, gamma=0.2, score=0.815174 -   3.2s\n",
      "[CV] n_estimators=300, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=300, gamma=0.2, score=0.807022 -   2.9s\n",
      "[CV] n_estimators=300, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=300, gamma=0.2, score=0.810282 -   2.7s\n",
      "[CV] n_estimators=250, gamma=0.3 .....................................\n",
      "[CV] ............ n_estimators=250, gamma=0.3, score=0.811039 -   2.2s\n",
      "[CV] n_estimators=250, gamma=0.3 .....................................\n",
      "[CV] ............ n_estimators=250, gamma=0.3, score=0.810425 -   2.2s\n",
      "[CV] n_estimators=250, gamma=0.3 .....................................\n",
      "[CV] ............ n_estimators=250, gamma=0.3, score=0.815317 -   2.3s\n",
      "[CV] n_estimators=250, gamma=0.3 .....................................\n",
      "[CV] ............ n_estimators=250, gamma=0.3, score=0.807310 -   2.5s\n",
      "[CV] n_estimators=250, gamma=0.3 .....................................\n",
      "[CV] ............ n_estimators=250, gamma=0.3, score=0.810650 -   2.5s\n",
      "[CV] n_estimators=350, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=350, gamma=0.2, score=0.810204 -   3.6s\n",
      "[CV] n_estimators=350, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=350, gamma=0.2, score=0.809623 -   3.4s\n",
      "[CV] n_estimators=350, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=350, gamma=0.2, score=0.814696 -   3.3s\n",
      "[CV] n_estimators=350, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=350, gamma=0.2, score=0.806696 -   3.1s\n",
      "[CV] n_estimators=350, gamma=0.2 .....................................\n",
      "[CV] ............ n_estimators=350, gamma=0.2, score=0.809447 -   3.2s\n",
      "[CV] n_estimators=40, gamma=0.3 ......................................\n",
      "[CV] ............. n_estimators=40, gamma=0.3, score=0.805274 -   0.4s\n",
      "[CV] n_estimators=40, gamma=0.3 ......................................\n",
      "[CV] ............. n_estimators=40, gamma=0.3, score=0.806645 -   0.5s\n",
      "[CV] n_estimators=40, gamma=0.3 ......................................\n",
      "[CV] ............. n_estimators=40, gamma=0.3, score=0.814591 -   0.5s\n",
      "[CV] n_estimators=40, gamma=0.3 ......................................\n",
      "[CV] ............. n_estimators=40, gamma=0.3, score=0.804059 -   0.4s\n",
      "[CV] n_estimators=40, gamma=0.3 ......................................\n",
      "[CV] ............. n_estimators=40, gamma=0.3, score=0.808860 -   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0.2, learning_rate=0.06, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=20, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0.9, reg_lambda=0.9,\n",
       "       scale_pos_weight=1, seed=3, silent=True, subsample=0.9),\n",
       "          fit_params={}, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'n_estimators': [20, 40, 70, 100, 200, 300, 350, 250, 320], 'gamma': [0.2, 0.3]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train[pred],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'gamma': 0.2}\n",
      "0.811674616512\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_) \n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred=[102, 25, 137, 136, 92, 109, 112, 19, 37, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
