{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version a but this version of numpy is 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version a but this version of numpy is 9"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "import matplotlib as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32769 entries, 0 to 32768\n",
      "Data columns (total 10 columns):\n",
      "ACTION              32769 non-null int64\n",
      "RESOURCE            32769 non-null int64\n",
      "MGR_ID              32769 non-null int64\n",
      "ROLE_ROLLUP_1       32769 non-null int64\n",
      "ROLE_ROLLUP_2       32769 non-null int64\n",
      "ROLE_DEPTNAME       32769 non-null int64\n",
      "ROLE_TITLE          32769 non-null int64\n",
      "ROLE_FAMILY_DESC    32769 non-null int64\n",
      "ROLE_FAMILY         32769 non-null int64\n",
      "ROLE_CODE           32769 non-null int64\n",
      "dtypes: int64(10)\n",
      "memory usage: 2.8 MB\n"
     ]
    }
   ],
   "source": [
    "#Read Datasets\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "y_train=train[\"ACTION\"]\n",
    "target='ACTION'\n",
    "\n",
    "ID=test['id']\n",
    "test=test.drop(['id'],axis=1)\n",
    "train.info()\n",
    "#test=test.drop(['id'],axis=1)\n",
    "#len(np.unique(train[\"ROLE_FAMILY_DESC\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shashank/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/shashank/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/shashank/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32769 entries, 0 to 32768\n",
      "Data columns (total 74 columns):\n",
      "RESOURCE                              32769 non-null int64\n",
      "MGR_ID                                32769 non-null int64\n",
      "ROLE_ROLLUP_1                         32769 non-null int64\n",
      "ROLE_ROLLUP_2                         32769 non-null int64\n",
      "ROLE_DEPTNAME                         32769 non-null int64\n",
      "ROLE_TITLE                            32769 non-null int64\n",
      "ROLE_FAMILY_DESC                      32769 non-null int64\n",
      "ROLE_FAMILY                           32769 non-null int64\n",
      "ROLE_CODE                             32769 non-null int64\n",
      "ROLE_FAMILYROLE_TITLE                 32769 non-null float64\n",
      "ROLE_FAMILYRESOURCE                   32769 non-null float64\n",
      "ROLE_FAMILYROLE_CODE                  32769 non-null float64\n",
      "ROLE_FAMILYROLE_ROLLUP_1              32769 non-null float64\n",
      "ROLE_FAMILYROLE_DEPTNAME              32769 non-null float64\n",
      "ROLE_FAMILYROLE_ROLLUP_2              32769 non-null float64\n",
      "ROLE_FAMILYMGR_ID                     32769 non-null float64\n",
      "ROLE_FAMILYROLE_FAMILY_DESC           32769 non-null float64\n",
      "ROLE_TITLERESOURCE                    32769 non-null float64\n",
      "ROLE_TITLEROLE_CODE                   32769 non-null float64\n",
      "ROLE_TITLEROLE_ROLLUP_1               32769 non-null float64\n",
      "ROLE_TITLEROLE_DEPTNAME               32769 non-null float64\n",
      "ROLE_TITLEROLE_ROLLUP_2               32769 non-null float64\n",
      "ROLE_TITLEMGR_ID                      32769 non-null float64\n",
      "ROLE_TITLEROLE_FAMILY_DESC            32769 non-null float64\n",
      "RESOURCEROLE_CODE                     32769 non-null float64\n",
      "RESOURCEROLE_ROLLUP_1                 32769 non-null float64\n",
      "RESOURCEROLE_DEPTNAME                 32769 non-null float64\n",
      "RESOURCEROLE_ROLLUP_2                 32769 non-null float64\n",
      "RESOURCEMGR_ID                        32769 non-null float64\n",
      "RESOURCEROLE_FAMILY_DESC              32769 non-null float64\n",
      "ROLE_CODEROLE_ROLLUP_1                32769 non-null float64\n",
      "ROLE_CODEROLE_DEPTNAME                32769 non-null float64\n",
      "ROLE_CODEROLE_ROLLUP_2                32769 non-null float64\n",
      "ROLE_CODEMGR_ID                       32769 non-null float64\n",
      "ROLE_CODEROLE_FAMILY_DESC             32769 non-null float64\n",
      "ROLE_ROLLUP_1ROLE_DEPTNAME            32769 non-null float64\n",
      "ROLE_ROLLUP_1ROLE_ROLLUP_2            32769 non-null float64\n",
      "ROLE_ROLLUP_1MGR_ID                   32769 non-null float64\n",
      "ROLE_ROLLUP_1ROLE_FAMILY_DESC         32769 non-null float64\n",
      "ROLE_DEPTNAMEROLE_ROLLUP_2            32769 non-null float64\n",
      "ROLE_DEPTNAMEMGR_ID                   32769 non-null float64\n",
      "ROLE_DEPTNAMEROLE_FAMILY_DESC         32769 non-null float64\n",
      "ROLE_ROLLUP_2MGR_ID                   32769 non-null float64\n",
      "ROLE_ROLLUP_2ROLE_FAMILY_DESC         32769 non-null float64\n",
      "MGR_IDROLE_FAMILY_DESC                32769 non-null float64\n",
      "RESOURCEMGR_IDROLE_ROLLUP_2           32769 non-null float64\n",
      "RESOURCEMGR_IDROLE_DEPTNAME           32769 non-null float64\n",
      "RESOURCEMGR_IDROLE_CODE               32769 non-null float64\n",
      "RESOURCEMGR_IDROLE_FAMILY_DESC        32769 non-null float64\n",
      "RESOURCEMGR_IDROLE_FAMILY             32769 non-null float64\n",
      "ROLE_FAMILYMGR_IDROLE_DEPTNAME        32769 non-null float64\n",
      "ROLE_FAMILYMGR_IDROLE_ROLLUP_2        32769 non-null float64\n",
      "RESOURCEROLE_DEPTNAMEROLE_FAMILY      32769 non-null float64\n",
      "RESOURCEROLE_DEPTNAMEROLE_ROLLUP_2    32769 non-null float64\n",
      "ROLE_FAMILYcount                      32769 non-null float64\n",
      "ROLE_TITLEcount                       32769 non-null float64\n",
      "RESOURCEcount                         32769 non-null int64\n",
      "ROLE_CODEcount                        32769 non-null float64\n",
      "ROLE_ROLLUP_1count                    32769 non-null float64\n",
      "ROLE_DEPTNAMEcount                    32769 non-null float64\n",
      "ROLE_ROLLUP_2count                    32769 non-null float64\n",
      "MGR_IDcount                           32769 non-null float64\n",
      "ROLE_FAMILY_DESCcount                 32769 non-null float64\n",
      "RESOURCE_enum                         32769 non-null int64\n",
      "MGR_ID_enum                           32769 non-null int64\n",
      "ROLE_ROLLUP_1_enum                    32769 non-null int64\n",
      "ROLE_ROLLUP_2_enum                    32769 non-null int64\n",
      "ROLE_DEPTNAME_enum                    32769 non-null int64\n",
      "ROLE_TITLE_enum                       32769 non-null int64\n",
      "ROLE_FAMILY_DESC_enum                 32769 non-null int64\n",
      "ROLE_FAMILY_enum                      32769 non-null int64\n",
      "ROLE_CODE_enum                        32769 non-null int64\n",
      "ACTION                                32769 non-null int64\n",
      "combination                           32769 non-null int64\n",
      "dtypes: float64(53), int64(21)\n",
      "memory usage: 18.8 MB\n"
     ]
    }
   ],
   "source": [
    "rows=train.shape[0]\n",
    "train=train.drop('ACTION',axis=1)\n",
    "result = pd.concat([train,test])\n",
    "for dfgs in predictors:\n",
    "    affiliate_channel_maxs = []\n",
    "    affiliate_channel_maxs_dict = {}\n",
    "    affiliate_channel_maxs = list(enumerate(np.unique(result[dfgs])))\n",
    "    affiliate_channel_maxs_dict = {name : i for i, name in affiliate_channel_maxs}\n",
    "    result[dfgs+'_enum'] = result[dfgs].map(lambda x: affiliate_channel_maxs_dict[x]).astype(int)\n",
    "new_train=result[:rows]\n",
    "new_train[target]=y_train\n",
    "new_test=result[rows:]\n",
    "new_train['combination']=new_train['MGR_ID_enum']*10000 + new_train['RESOURCE_enum']\n",
    "new_test['combination']=new_test['MGR_ID_enum']*10000 + new_test['RESOURCE_enum']\n",
    "new_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RESOURCE',\n",
       " 'MGR_ID',\n",
       " 'ROLE_ROLLUP_1',\n",
       " 'ROLE_ROLLUP_2',\n",
       " 'ROLE_DEPTNAME',\n",
       " 'ROLE_TITLE',\n",
       " 'ROLE_FAMILY_DESC',\n",
       " 'ROLE_FAMILY',\n",
       " 'ROLE_CODE']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target='ACTION'\n",
    "predictors = [x for x in train.columns if x not in target]\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#new_test=new_test.fillna(0)\n",
    "#new_test.info()\n",
    "new_train.to_csv(\"new_train.csv\")\n",
    "new_test.to_csv(\"new_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(class_weight='balanced')\n",
    "log_model.fit(train[predictors],train[target])\n",
    "log_model.score(train[predictors],train[target])\n",
    "# ID=test['id']\n",
    "# test=test.drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=test.fillna(value=0)\n",
    "predicted = log_model.predict_proba(test)[:,1]\n",
    "#np.unique(predicted)\n",
    "preds = pd.DataFrame({\"Id\":ID,\"ACTION\":predicted})\n",
    "preds = preds.set_index('Id')\n",
    "preds.to_csv('logistic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1-0 Encoding\n",
    "for f in train.columns:\n",
    "    print f\n",
    "    df_all_dummy = pd.get_dummies(train[f], prefix=f)\n",
    "    train = train.drop([f], axis=1)\n",
    "    train = pd.concat((train, df_all_dummy), axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1-0 Encoding\n",
    "test=test.drop(['id'],axis=1)\n",
    "for f in test.columns:\n",
    "    print f\n",
    "    df_all_dummy = pd.get_dummies(test[f], prefix=f)\n",
    "    test = test.drop([f], axis=1)\n",
    "    test = pd.concat((test, df_all_dummy), axis=1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Copy of data\n",
    "test_back=test\n",
    "train_back=train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#XGboost\n",
    "\n",
    "# gbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(train, y_train)\n",
    "param = {'max_depth':4, 'eta':1, 'silent':1, 'objective':'binary:logistic'}\n",
    "num_round = 2\n",
    "dtr=xgb.DMatrix(train,label=y_train)\n",
    "gb = xgb.cv(params=param, dtrain=dtr, num_boost_round = num_round, nfold= 5)\n",
    "gb.shape[0]\n",
    "#predicted = gbm.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Learning Rate\n",
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    feat=[]\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics=[\"auc\"] , early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain[target],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain[target].values, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob)\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    print feat_imp\n",
    "    #feat.append(feat_imp)\n",
    "    #return feat\n",
    "    #.plot(kind='bar', title='Feature Importances')\n",
    "    #plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0.2, learning_rate=0.3, max_delta_step=0, max_depth=18,\n",
       "       min_child_weight=6, missing=None, n_estimators=120, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0.2, reg_lambda=0.2,\n",
       "       scale_pos_weight=1, seed=1234567890, silent=True, subsample=0.9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.3,\n",
    " n_estimators=120,\n",
    " max_depth=18,\n",
    " min_child_weight=6,\n",
    " gamma=0.2,\n",
    " reg_alpha=0.2,\n",
    " reg_lambda=0.2,\n",
    " subsample=0.9,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " #nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=0)\n",
    "#modelfit(xgb1, train, predictors)\n",
    "xgb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(\n",
    "    xgb1,\n",
    "    {\n",
    "        #'learning_rate':[i/10.0 for i in range(1,4)],\n",
    "         #'min_child_weight': [5,6,7,8],\n",
    "         #'max_depth': [10,13,14,18,20],\n",
    "         #'n_estimators': range(15,18),\n",
    "        #'gamma':[i/10.0 for i in range(2,4)],\n",
    "        #'reg_alpha':[0.2,0.3,0.4,0.5],\n",
    "        #'reg_lambda':[0.3,0.4,0.5,0.6]\n",
    "        #'colsample_bytree': [0.6,0.7,0.8,0.85,0.9],\n",
    "    },\n",
    "    cv=5,\n",
    "    n_jobs=1,\n",
    "    verbose=5,\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_test1 = { 'max_depth':range(3,7,2),'min_child_weight':range(1,4,2)}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.5, n_estimators=15, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=0), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "\n",
    "gsearch1.fit(train[predictors],train[target])\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(clf.best_params_) \n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# params = {}\n",
    "# params[\"objective\"] = \"binary:logistic\"\n",
    "# params[\"n_estimators\"] = \"17\"\n",
    "# params[\"eval_metric\"] = \"auc\"\n",
    "# params[\"min_child_weight\"] = 6\n",
    "# params[\"max_depth\"] = 18\n",
    "# params[\"learning_rate\"] =0.3\n",
    "# params['gamma']=0.2,\n",
    "\n",
    "# params['subsample']=0.8,\n",
    "# params[\"colsample_bytree\"]= 0.8\n",
    "# params['nthread']=4,\n",
    "# params['scale_pos_weight']=1,\n",
    "\n",
    "#test=test.drop(['id'],axis=1)\n",
    "#xg_dtst = xgb.DMatrix(test)\n",
    "#xg_dtrn = xgb.DMatrix(train[predictors], label=y_train)\n",
    "#model = xgb.train(list(params.items()), xg_dtrn)\n",
    "#test.info()\n",
    "#predicted = model.predict(xg_dtst)\n",
    "\n",
    "# train=train.drop(['MGR_ID'],axis=1)\n",
    "# test=test.drop(['MGR_ID'],axis=1)\n",
    "# predictors.remove('MGR_ID')\n",
    "\n",
    "model = xgb1.fit(train[predictors], train['ACTION'], eval_metric='auc')\n",
    "predict_ac = xgb1.predict(test[predictors])\n",
    "predicted = xgb1.predict_proba(test[predictors])[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write Submission\n",
    "preds = pd.DataFrame({\"Id\":ID,\"ACTION\":predicted})\n",
    "preds = preds.set_index('Id')\n",
    "preds.to_csv('xgboost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "new_train=pd.DataFrame(poly.fit_transform(train[predictors]))\n",
    "new_train[target]=train[target]\n",
    "new_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_test=pd.DataFrame(poly.fit_transform(test))\n",
    "new_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE_FAMILY ROLE_TITLE\n",
      "ROLE_FAMILY RESOURCE\n",
      "ROLE_FAMILY ROLE_CODE\n",
      "ROLE_FAMILY ROLE_ROLLUP_1\n",
      "ROLE_FAMILY ROLE_DEPTNAME\n",
      "ROLE_FAMILY ROLE_ROLLUP_2\n",
      "ROLE_FAMILY MGR_ID\n",
      "ROLE_FAMILY ROLE_FAMILY_DESC\n",
      "ROLE_TITLE RESOURCE\n",
      "ROLE_TITLE ROLE_CODE\n",
      "ROLE_TITLE ROLE_ROLLUP_1\n",
      "ROLE_TITLE ROLE_DEPTNAME\n",
      "ROLE_TITLE ROLE_ROLLUP_2\n",
      "ROLE_TITLE MGR_ID\n",
      "ROLE_TITLE ROLE_FAMILY_DESC\n",
      "RESOURCE ROLE_CODE\n",
      "RESOURCE ROLE_ROLLUP_1\n",
      "RESOURCE ROLE_DEPTNAME\n",
      "RESOURCE ROLE_ROLLUP_2\n",
      "RESOURCE MGR_ID\n",
      "RESOURCE ROLE_FAMILY_DESC\n",
      "ROLE_CODE ROLE_ROLLUP_1\n",
      "ROLE_CODE ROLE_DEPTNAME\n",
      "ROLE_CODE ROLE_ROLLUP_2\n",
      "ROLE_CODE MGR_ID\n",
      "ROLE_CODE ROLE_FAMILY_DESC\n",
      "ROLE_ROLLUP_1 ROLE_DEPTNAME\n",
      "ROLE_ROLLUP_1 ROLE_ROLLUP_2\n",
      "ROLE_ROLLUP_1 MGR_ID\n",
      "ROLE_ROLLUP_1 ROLE_FAMILY_DESC\n",
      "ROLE_DEPTNAME ROLE_ROLLUP_2\n",
      "ROLE_DEPTNAME MGR_ID\n",
      "ROLE_DEPTNAME ROLE_FAMILY_DESC\n",
      "ROLE_ROLLUP_2 MGR_ID\n",
      "ROLE_ROLLUP_2 ROLE_FAMILY_DESC\n",
      "MGR_ID ROLE_FAMILY_DESC\n",
      "ROLE_FAMILY ROLE_TITLE RESOURCE\n",
      "ROLE_FAMILY ROLE_TITLE ROLE_CODE\n",
      "ROLE_FAMILY ROLE_TITLE ROLE_ROLLUP_1\n",
      "ROLE_FAMILY ROLE_TITLE ROLE_DEPTNAME\n",
      "ROLE_FAMILY ROLE_TITLE ROLE_ROLLUP_2\n",
      "ROLE_FAMILY ROLE_TITLE MGR_ID\n",
      "ROLE_FAMILY ROLE_TITLE ROLE_FAMILY_DESC\n",
      "ROLE_FAMILY RESOURCE ROLE_CODE\n",
      "ROLE_FAMILY RESOURCE ROLE_ROLLUP_1\n",
      "ROLE_FAMILY RESOURCE ROLE_DEPTNAME\n",
      "ROLE_FAMILY RESOURCE ROLE_ROLLUP_2\n",
      "ROLE_FAMILY RESOURCE MGR_ID\n",
      "ROLE_FAMILY RESOURCE ROLE_FAMILY_DESC\n",
      "ROLE_FAMILY ROLE_CODE ROLE_ROLLUP_1\n",
      "ROLE_FAMILY ROLE_CODE ROLE_DEPTNAME\n",
      "ROLE_FAMILY ROLE_CODE ROLE_ROLLUP_2\n",
      "ROLE_FAMILY ROLE_CODE MGR_ID\n",
      "ROLE_FAMILY ROLE_CODE ROLE_FAMILY_DESC\n",
      "ROLE_FAMILY ROLE_ROLLUP_1 ROLE_DEPTNAME\n",
      "ROLE_FAMILY ROLE_ROLLUP_1 ROLE_ROLLUP_2\n",
      "ROLE_FAMILY ROLE_ROLLUP_1 MGR_ID\n",
      "ROLE_FAMILY ROLE_ROLLUP_1 ROLE_FAMILY_DESC\n",
      "ROLE_FAMILY ROLE_DEPTNAME ROLE_ROLLUP_2\n",
      "ROLE_FAMILY ROLE_DEPTNAME MGR_ID\n",
      "ROLE_FAMILY ROLE_DEPTNAME ROLE_FAMILY_DESC\n",
      "ROLE_FAMILY ROLE_ROLLUP_2 MGR_ID\n",
      "ROLE_FAMILY ROLE_ROLLUP_2 ROLE_FAMILY_DESC\n",
      "ROLE_FAMILY MGR_ID ROLE_FAMILY_DESC\n",
      "ROLE_TITLE RESOURCE ROLE_CODE\n",
      "ROLE_TITLE RESOURCE ROLE_ROLLUP_1\n",
      "ROLE_TITLE RESOURCE ROLE_DEPTNAME\n",
      "ROLE_TITLE RESOURCE ROLE_ROLLUP_2\n",
      "ROLE_TITLE RESOURCE MGR_ID\n",
      "ROLE_TITLE RESOURCE ROLE_FAMILY_DESC\n",
      "ROLE_TITLE ROLE_CODE ROLE_ROLLUP_1\n",
      "ROLE_TITLE ROLE_CODE ROLE_DEPTNAME\n",
      "ROLE_TITLE ROLE_CODE ROLE_ROLLUP_2\n",
      "ROLE_TITLE ROLE_CODE MGR_ID\n",
      "ROLE_TITLE ROLE_CODE ROLE_FAMILY_DESC\n",
      "ROLE_TITLE ROLE_ROLLUP_1 ROLE_DEPTNAME\n",
      "ROLE_TITLE ROLE_ROLLUP_1 ROLE_ROLLUP_2\n",
      "ROLE_TITLE ROLE_ROLLUP_1 MGR_ID\n",
      "ROLE_TITLE ROLE_ROLLUP_1 ROLE_FAMILY_DESC\n",
      "ROLE_TITLE ROLE_DEPTNAME ROLE_ROLLUP_2\n",
      "ROLE_TITLE ROLE_DEPTNAME MGR_ID\n",
      "ROLE_TITLE ROLE_DEPTNAME ROLE_FAMILY_DESC\n",
      "ROLE_TITLE ROLE_ROLLUP_2 MGR_ID\n",
      "ROLE_TITLE ROLE_ROLLUP_2 ROLE_FAMILY_DESC\n",
      "ROLE_TITLE MGR_ID ROLE_FAMILY_DESC\n",
      "RESOURCE ROLE_CODE ROLE_ROLLUP_1\n",
      "RESOURCE ROLE_CODE ROLE_DEPTNAME\n",
      "RESOURCE ROLE_CODE ROLE_ROLLUP_2\n",
      "RESOURCE ROLE_CODE MGR_ID\n",
      "RESOURCE ROLE_CODE ROLE_FAMILY_DESC\n",
      "RESOURCE ROLE_ROLLUP_1 ROLE_DEPTNAME\n",
      "RESOURCE ROLE_ROLLUP_1 ROLE_ROLLUP_2\n",
      "RESOURCE ROLE_ROLLUP_1 MGR_ID\n",
      "RESOURCE ROLE_ROLLUP_1 ROLE_FAMILY_DESC\n",
      "RESOURCE ROLE_DEPTNAME ROLE_ROLLUP_2\n",
      "RESOURCE ROLE_DEPTNAME MGR_ID\n",
      "RESOURCE ROLE_DEPTNAME ROLE_FAMILY_DESC\n",
      "RESOURCE ROLE_ROLLUP_2 MGR_ID\n",
      "RESOURCE ROLE_ROLLUP_2 ROLE_FAMILY_DESC\n",
      "RESOURCE MGR_ID ROLE_FAMILY_DESC\n",
      "ROLE_CODE ROLE_ROLLUP_1 ROLE_DEPTNAME\n",
      "ROLE_CODE ROLE_ROLLUP_1 ROLE_ROLLUP_2\n",
      "ROLE_CODE ROLE_ROLLUP_1 MGR_ID\n",
      "ROLE_CODE ROLE_ROLLUP_1 ROLE_FAMILY_DESC\n",
      "ROLE_CODE ROLE_DEPTNAME ROLE_ROLLUP_2\n",
      "ROLE_CODE ROLE_DEPTNAME MGR_ID\n",
      "ROLE_CODE ROLE_DEPTNAME ROLE_FAMILY_DESC\n",
      "ROLE_CODE ROLE_ROLLUP_2 MGR_ID\n",
      "ROLE_CODE ROLE_ROLLUP_2 ROLE_FAMILY_DESC\n",
      "ROLE_CODE MGR_ID ROLE_FAMILY_DESC\n",
      "ROLE_ROLLUP_1 ROLE_DEPTNAME ROLE_ROLLUP_2\n",
      "ROLE_ROLLUP_1 ROLE_DEPTNAME MGR_ID\n",
      "ROLE_ROLLUP_1 ROLE_DEPTNAME ROLE_FAMILY_DESC\n",
      "ROLE_ROLLUP_1 ROLE_ROLLUP_2 MGR_ID\n",
      "ROLE_ROLLUP_1 ROLE_ROLLUP_2 ROLE_FAMILY_DESC\n",
      "ROLE_ROLLUP_1 MGR_ID ROLE_FAMILY_DESC\n",
      "ROLE_DEPTNAME ROLE_ROLLUP_2 MGR_ID\n",
      "ROLE_DEPTNAME ROLE_ROLLUP_2 ROLE_FAMILY_DESC\n",
      "ROLE_DEPTNAME MGR_ID ROLE_FAMILY_DESC\n",
      "ROLE_ROLLUP_2 MGR_ID ROLE_FAMILY_DESC\n"
     ]
    }
   ],
   "source": [
    "#Value_Counts 2-way\n",
    "num=len(train.index)\n",
    "#removed1=['ROLE_TITLE','ROLE_FAMILY']\n",
    "#removed2=['ROLE_ROLLUP_1','ROLE_ROLLUP_2']\n",
    "way2iter=set(train.columns).difference(set(['ACTION']))\n",
    "for i,j in itertools.combinations(way2iter,2):\n",
    "    print i,j\n",
    "    #if ((i in removed1) & (j=='ROLE_CODE')) or ((i=='ROLE_CODE') & (j in removed2)):\n",
    "    #    continue\n",
    "    new=dict(train.groupby([i,j])[j].count())\n",
    "    train[i+j]=pd.Series(zip(train[i],train[j])).map(new)\n",
    "    test[i+j]=pd.Series(zip(test[i],test[j])).map(new)\n",
    "#train.head()\n",
    "# way3lis=[(\"RESOURCE\", \"MGR_ID\", \"ROLE_ROLLUP_2\"), \n",
    "# (\"RESOURCE\", \"MGR_ID\", \"ROLE_DEPTNAME\"),\n",
    "# (\"RESOURCE\", \"MGR_ID\", \"ROLE_CODE\"),\n",
    "# (\"RESOURCE\", \"MGR_ID\", \"ROLE_FAMILY_DESC\"),\n",
    "# (\"RESOURCE\", \"MGR_ID\", \"ROLE_FAMILY\"),\n",
    "# (\"ROLE_FAMILY\", \"MGR_ID\", \"ROLE_DEPTNAME\"),\n",
    "# (\"ROLE_FAMILY\", \"MGR_ID\", \"ROLE_ROLLUP_2\"),\n",
    "# (\"RESOURCE\", \"ROLE_DEPTNAME\", \"ROLE_FAMILY\"),\n",
    "# (\"RESOURCE\", \"ROLE_DEPTNAME\", \"ROLE_ROLLUP_2\")]\n",
    "#3way\n",
    "for (i,j,k) in itertools.combinations(way2iter,3):\n",
    "    print i,j,k\n",
    "    #if (((i in removed1) & (j=='ROLE_CODE')) or ((i=='ROLE_CODE') & (j in removed2))) or (((j in removed1) & (k=='ROLE_CODE')) or ((j=='ROLE_CODE') & (k in removed2))):\n",
    "    #    continue\n",
    "    new=dict(train.groupby([i,j,k])[j].count())\n",
    "    train[i+j+k]=pd.Series(zip(train[i],train[j],train[k])).map(new)\n",
    "    test[i+j+k]=pd.Series(zip(test[i],test[j],test[k])).map(new)\n",
    "#train.head()\n",
    "\n",
    "#Value_Counts 1-way\n",
    "for i in way2iter:\n",
    "    counts_tot=dict(train[i].value_counts())\n",
    "    train[i+'count']=train[i].map(counts_tot)\n",
    "    test[i+'count']=test[i].map(counts_tot)\n",
    "    test=test.fillna(value=0)\n",
    "\n",
    "\n",
    "#train=train.drop([\"ROLE_ROLLUP_1\",\"ROLE_ROLLUP_2\"],axis=1)\n",
    "#test=test.drop([\"ROLE_ROLLUP_1\",\"ROLE_ROLLUP_2\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['combination']=train['MGR_ID']*10000 + train['RESOURCE']\n",
    "test['combination']=test['MGR_ID']*10000 + test['RESOURCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['combination2']=train['MGR_ID']*10000 + train['ROLE_FAMILY_DESC']\n",
    "test['combination2']=test['MGR_ID']*10000 + test['ROLE_FAMILY_DESC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769, 141)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new[(56723, 75078)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['MGR_ID'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip(train['MGR_ID'],train['RESOURCE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/shashank/Downloads/PS 3/En/blendingRF,XG,ET,XG,GB.csv', '/Users/shashank/Downloads/PS 3/En/xgboost140feat_all_way_no_enum.csv']\n",
      "parsing: /Users/shashank/Downloads/PS 3/En/blendingRF,XG,ET,XG,GB.csv\n",
      "parsing: /Users/shashank/Downloads/PS 3/En/xgboost140feat_all_way_no_enum.csv\n",
      "wrote to out.csv\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "\n",
    "glob_files = os.getcwd()+'/En/*.csv'\n",
    "print glob(glob_files)\n",
    "loc_outfile = 'out.csv'\n",
    "\n",
    "def kaggle_bag(glob_files, loc_outfile, weights=[], method=\"average\"):\n",
    "  if method == \"average\":\n",
    "    scores = defaultdict(float)\n",
    "  with open(loc_outfile,\"wb\") as outfile:\n",
    "    for i, glob_file in enumerate( glob(glob_files) ):\n",
    "      print \"parsing:\", glob_file\n",
    "      # sort glob_file by first column, ignoring the first line\n",
    "      lines = open(glob_file).readlines()\n",
    "      lines = [lines[0]] + sorted(lines[1:])\n",
    "      for e, line in enumerate( lines ):\n",
    "        if i == 0 and e == 0:\n",
    "          outfile.write(line)\n",
    "        if e > 0:\n",
    "          row = line.strip().split(\",\")\n",
    "          if scores[(e,row[0])] == 0:\n",
    "            scores[(e,row[0])] = 1\n",
    "          scores[(e,row[0])] *= float(row[1])\n",
    "    for j,k in sorted(scores):\n",
    "      outfile.write(\"%s,%f\\n\"%(k,math.pow(scores[(j,k)],1/(i+1))))\n",
    "    print(\"wrote to %s\"%loc_outfile)\n",
    "\n",
    "kaggle_bag(glob_files, loc_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing: 0 /Users/shashank/Downloads/PS 3/En/final.csv\n",
      "parsing: 1 /Users/shashank/Downloads/PS 3/En/blending.csv\n",
      "wrote to out.csv\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "\n",
    "def kaggle_bag(array, loc_outfile, weights=[0.8,0.2],method=\"average\"):\n",
    "  if method == \"average\":\n",
    "    scores = defaultdict(float)\n",
    "  with open(loc_outfile,\"wb\") as outfile:\n",
    "    for i, glob_file in enumerate(array):\n",
    "      print \"parsing:\", i,glob_file\n",
    "      # sort glob_file by first column, ignoring the first line\n",
    "      lines = open(glob_file).readlines()\n",
    "      lines = [lines[0]] + sorted(lines[1:])\n",
    "      for e, line in enumerate( lines ):\n",
    "        if i == 0 and e == 0:\n",
    "          outfile.write(line)\n",
    "        if e > 0:\n",
    "          row = line.strip().split(\",\")\n",
    "          scores[(e,row[0])] += float(row[1])*weights[i]\n",
    "    for j,k in sorted(scores):\n",
    "      outfile.write(\"%s,%f\\n\"%(k,(scores[(j,k)])))\n",
    "    print(\"wrote to %s\"%loc_outfile)\n",
    "array=[ os.getcwd()+'/En/final.csv', os.getcwd()+'/En/blending.csv']\n",
    "\n",
    "kaggle_bag(array, loc_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=2\n",
    "b=3\n",
    "str(a)+str(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25988.957978577313"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['MGR_ID'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=5, n_iter=5,\n",
       "       random_state=42, tol=0.0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "X = sparse_random_matrix(100, 100, density=0.01, random_state=42)\n",
    "svd = TruncatedSVD(n_components=5, random_state=42)\n",
    "svd.fit(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58921, 140)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
